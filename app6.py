import streamlit as st
import pandas_ta as ta
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import sys
import re
import importlib.util
import json
import time
import os
import random
import requests
import xml.etree.ElementTree as ET
import xgboost as xgb  # <--- æ–°å¢é€™è¡Œ
from sklearn.metrics import accuracy_score # <--- æ–°å¢é€™è¡Œ
import lightgbm as lgb
from catboost import CatBoostClassifier

def download_tw_stock_data(ticker):
    """
    è°æ˜çš„å°è‚¡ä¸‹è¼‰å™¨ï¼šè‡ªå‹•è™•ç† .TW/.TWO å¾Œç¶´ï¼Œä¸¦ä¿®æ­£ç©ºå€¼æ•¸æ“š
    """
    # 1. è‡ªå‹•ä¿®æ­£ä»£è™Ÿæ ¼å¼
    target_ticker = ticker.upper()
    if not (target_ticker.endswith(".TW") or target_ticker.endswith(".TWO")):
        # å…ˆå˜—è©¦åŠ ä¸Š .TW (ä¸Šå¸‚)
        test_data = yf.download(f"{target_ticker}.TW", period="5d", progress=False)
        if not test_data.empty:
            target_ticker = f"{target_ticker}.TW"
        else:
            # å¦‚æœæŠ“ä¸åˆ°ï¼Œå˜—è©¦ .TWO (ä¸Šæ«ƒ)
            target_ticker = f"{target_ticker}.TWO"
    
    st.write(f"ğŸ”„ æ­£åœ¨é–å®šå°è‚¡ç›®æ¨™ï¼š{target_ticker}")

    # 2. ä¸‹è¼‰æ•¸æ“š (é€£åŒç¾è‚¡å°ç…§çµ„ä¸€èµ·æŠ“)
    # é€™è£¡æˆ‘å€‘ä¸€å®šè¦æŠ“ï¼šè²»åŠ(^SOX) å’Œ è¼é”(NVDA) ä½œç‚ºé ˜å…ˆæŒ‡æ¨™
    tickers_to_download = [target_ticker, "^SOX", "NVDA"]
    data = yf.download(tickers_to_download, period="5y", interval="1d", progress=False)
    
    # è™•ç† MultiIndex (Yahoo ä¸‹è¼‰å¤šæª”è‚¡ç¥¨æ™‚çš„æ ¼å¼å•é¡Œ)
    if isinstance(data.columns, pd.MultiIndex):
        # åªå– Close æ”¶ç›¤åƒ¹
        df = data['Close'].copy()
    else:
        df = data['Close'].copy()
        
    # 3. é˜²é›·è™•ç†ï¼šä¿®æ­£å°è‚¡ç‰¹æœ‰çš„ã€Œé›¶æˆäº¤é‡ã€æˆ–ã€Œé¢±é¢¨å‡ã€å•é¡Œ
    # å¦‚æœæŸå¤©å°è‚¡æ˜¯ NaN (ä¾‹å¦‚é¢±é¢¨å‡)ï¼Œä½†ç¾è‚¡æœ‰è³‡æ–™ï¼Œæˆ‘å€‘ç”¨å‰ä¸€å¤©çš„å°è‚¡æ”¶ç›¤åƒ¹å¡«è£œ (ffill)
    df.ffill(inplace=True)
    df.dropna(inplace=True)
    
    # å›å‚³è™•ç†å¥½çš„ DataFrame å’Œ ä¿®æ­£å¾Œçš„ä»£è™Ÿ
    return df, target_ticker

# ==========================================
# â˜…â˜…â˜… è«‹è£œä¸Šé€™å€‹éºå¤±çš„é—œéµå‡½æ•¸ï¼ â˜…â˜…â˜…
# ==========================================
def get_real_live_price(symbol):
    try:
        # å˜—è©¦å¾ yfinance å¿«é€Ÿç²å–
        t = yf.Ticker(symbol)
        price = t.fast_info.get('last_price')
        
        # å¦‚æœå¤±æ•—ï¼Œæ”¹ç”¨ä¸‹è¼‰æ•¸æ“šæ–¹å¼
        if price is None or np.isnan(price):
            df = yf.download(symbol, period='1d', interval='1m', progress=False)
            if not df.empty:
                if isinstance(df.columns, pd.MultiIndex): 
                    df.columns = df.columns.get_level_values(0)
                return float(df['Close'].iloc[-1])
                
        return float(price) if price else None
    except: 
        return None

# ==========================================
# â˜…â˜…â˜… 0. God Mode: é–å®šéš¨æ©Ÿç¨®å­ â˜…â˜…â˜…
# ==========================================
def set_seeds(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    try:
        import tensorflow as tf
        tf.random.set_seed(seed)
    except: pass

set_seeds(42)

# ==========================================
# â˜…â˜…â˜… 1. å¥—ä»¶æª¢æŸ¥ â˜…â˜…â˜…
# ==========================================
try:
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')
except: pass

try:
    from sklearn.preprocessing import StandardScaler
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, LSTM, Dropout
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping
    HAS_TENSORFLOW = True
except ImportError:
    HAS_TENSORFLOW = False

HAS_TRANSFORMERS = importlib.util.find_spec("transformers") is not None
try:
    import google.generativeai as genai
    HAS_GEMINI = True
except: HAS_GEMINI = False

# ==========================================
# 2. é é¢è¨­å®š
# ==========================================
st.set_page_config(
    page_title="2026 é‡åŒ–æˆ°æƒ…å®¤ (Ultimate v22.4)",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
        .stApp { background-color: #0e1117; }
        h1, h2, h3, h4, h5, h6, span, div, p { color: #d1d4dc !important; font-family: 'Roboto', sans-serif; }
        div[data-testid="stMetric"] { background-color: #1c202a; border: 1px solid #2a2e39; border-radius: 8px; padding: 10px; }
        div[data-testid="stMetricLabel"] > div { color: #787b86 !important; }
        div[data-testid="stMetricValue"] > div { color: #d1d4dc !important; }
        section[data-testid="stSidebar"] { background-color: #161920; border-right: 1px solid #2a2e39; }
        .stButton > button { background-color: #2962ff; color: white; border: none; border-radius: 4px; font-weight: 600; }
        .stButton > button:hover { background-color: #1e4bd1; }
        .stTabs [data-baseweb="tab-list"] { gap: 10px; }
        .stTabs [data-baseweb="tab"] { background-color: #1c202a; border-radius: 4px 4px 0 0; color: #d1d4dc; }
        .stTabs [aria-selected="true"] { background-color: #2962ff; color: white; }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# â˜…â˜…â˜… æ ¸å¿ƒæ¨¡çµ„ï¼šAI äº¤æ˜“è³‡æ–™åº« (Google Sheets é›²ç«¯ç‰ˆ) â˜…â˜…â˜…
# ==========================================
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# è«‹å¡«å…¥ä½ çš„ Google Sheet ç¶²å€ (å¿…é ˆå…ˆå°‡ Sheet åˆ†äº«çµ¦æœå‹™å¸³è™Ÿ Email)
SHEET_URL = "https://docs.google.com/spreadsheets/d/1hNsWxQq3aYD7msroBVJdMnC6vA64khsSUF90yIKeS7w/edit?gid=0#gid=0"

# é€£ç·šå¿«å– (é¿å…æ¯æ¬¡æŒ‰æŒ‰éˆ•éƒ½é‡æ–°é€£ç·š)
@st.cache_resource
def get_gsheet_connection():
    try:
        # å¾ st.secrets è®€å–æ†‘è­‰
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        # é€™è£¡å‡è¨­ä½ åœ¨ secrets è£¡çš„æ¨™é¡Œæ˜¯ gcp_service_account
        creds_dict = dict(st.secrets["gcp_service_account"])
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        return None

def init_db():
    """æª¢æŸ¥ä¸¦åˆå§‹åŒ– Sheet (å¦‚æœæ²’æ¨™é¡Œå°±åŠ ä¸Š)"""
    client = get_gsheet_connection()
    if not client: return
    try:
        sheet = client.open_by_url(SHEET_URL).sheet1
        # æª¢æŸ¥ç¬¬ä¸€åˆ—æ˜¯å¦ç‚ºæ¨™é¡Œï¼Œå¦‚æœç©ºå‰‡åˆå§‹åŒ–
        if not sheet.row_values(1):
            sheet.append_row(["date", "symbol", "direction", "confidence", "entry_price", "status", "exit_price", "return_pct"])
    except: pass

# ç¢ºä¿ Sheet å·²æº–å‚™å¥½
init_db()

def save_prediction_db(symbol, direction, confidence, entry_price):
    """å­˜å…¥ä¸€ç­†æ–°çš„é æ¸¬ (Append Row)"""
    client = get_gsheet_connection()
    if not client: return False, "âŒ ç„¡æ³•é€£ç·š Google Sheets (è«‹æª¢æŸ¥ Secrets)"
    
    try:
        sheet = client.open_by_url(SHEET_URL).sheet1
        today_str = datetime.now().strftime('%Y-%m-%d')
        
        # è®€å–æ‰€æœ‰è³‡æ–™æª¢æŸ¥é‡è¤‡ (ç¨å¾®è€—æ™‚ï¼Œä½†å®‰å…¨)
        records = sheet.get_all_records()
        df = pd.DataFrame(records)
        
        if not df.empty:
            # ç¢ºä¿æ¬„ä½éƒ½æ˜¯å­—ä¸²ä»¥é€²è¡Œæ¯”å°
            if not df[(df['date'].astype(str) == today_str) & (df['symbol'] == symbol)].empty:
                return False, "âš ï¸ ä»Šå¤©å·²ç¶“è¨˜éŒ„éäº† (é›²ç«¯)"

        # æ’å…¥æ–°ç´€éŒ„
        # æ³¨æ„ï¼šGSpread å¯«å…¥æ™‚æ•¸å€¼æœ€å¥½è½‰ç‚ºæ¨™æº–æ ¼å¼
        new_row = [today_str, symbol, direction, float(confidence), float(entry_price), "Pending", 0.0, 0.0]
        sheet.append_row(new_row)
        return True, "âœ… æˆ°å ±å·²ä¸Šå‚³é›²ç«¯ï¼"
    except Exception as e:
        return False, f"âŒ ä¸Šå‚³å¤±æ•—: {e}"

def get_history_df(symbol=None):
    """è®€å–æ­·å²è³‡æ–™ (å¾é›²ç«¯ä¸‹è¼‰)"""
    client = get_gsheet_connection()
    if not client: return pd.DataFrame()
    
    try:
        sheet = client.open_by_url(SHEET_URL).sheet1
        records = sheet.get_all_records()
        df = pd.DataFrame(records)
        
        if df.empty: return df
        
        # ç°¡å–®çš„å‹åˆ¥è½‰æ›
        df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')
        df['entry_price'] = pd.to_numeric(df['entry_price'], errors='coerce')
        df['return_pct'] = pd.to_numeric(df['return_pct'], errors='coerce')
        
        if symbol:
            df = df[df['symbol'] == symbol].copy()
            
        df = df.sort_values(by="date", ascending=True)
        return df
    except: return pd.DataFrame()

def verify_performance_db():
    """è‡ªå‹•é©—è­‰ç¸¾æ•ˆ (æ‰¹é‡æ›´æ–°é›²ç«¯)"""
    client = get_gsheet_connection()
    if not client: return 0
    
    try:
        sheet = client.open_by_url(SHEET_URL).sheet1
        # è®€å–å…¨éƒ¨è³‡æ–™
        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        
        if df.empty: return 0
        
        updates = 0
        has_change = False
        
        # éæ­·è³‡æ–™æª¢æŸ¥ Pending
        for index, row in df.iterrows():
            if row['status'] == 'Pending':
                sym = row['symbol']
                entry = float(row['entry_price'])
                direction = row['direction']
                
                curr_price = get_real_live_price(sym)
                if curr_price:
                    ret = (curr_price - entry) / entry
                    new_status = "Pending"
                    
                    # é©—è­‰é‚è¼¯
                    if direction == "Bull":
                        if ret > 0.02: new_status = "Win"
                        elif ret < -0.02: new_status = "Loss"
                    elif direction == "Bear":
                        if ret < -0.02: new_status = "Win"
                        elif ret > 0.02: new_status = "Loss"
                    
                    if new_status != "Pending":
                        # æ›´æ–° DataFrame
                        df.at[index, 'status'] = new_status
                        df.at[index, 'exit_price'] = curr_price
                        df.at[index, 'return_pct'] = ret * 100
                        has_change = True
                        updates += 1
        
        if has_change:
            # â˜… é—œéµï¼šGSpread æ›´æ–°æ•´å¼µè¡¨æ¯”ä¸€æ ¼ä¸€æ ¼æ”¹å¿«ä¸”ç©©å®š
            # æº–å‚™å¯«å…¥çš„è³‡æ–™ (åŒ…å«æ¨™é¡Œ)
            header = df.columns.values.tolist()
            values = df.values.tolist()
            # æ¸…ç©ºä¸¦é‡å¯«
            sheet.clear()
            sheet.update([header] + values)
            
        return updates
    # â˜…â˜…â˜… ä¿®å¾© SyntaxError: è£œå›é€™è£¡éºå¤±çš„ except â˜…â˜…â˜…
    except Exception as e:
        print(f"Verify Error: {e}")
        return 0

# ==========================================
# â˜…â˜…â˜… TSM T+5 ä¸»å¸¥ç‰ˆ (çµ•å°é˜²å´©æ½°æ•‘å‘½ç‰ˆ) â˜…â˜…â˜…
# ==========================================
# 1. å®šç¾©ä¿¡å¿ƒæ”¾å¤§å‡½æ•¸ (ç¢ºä¿å‡½æ•¸å­˜åœ¨)
def enhance_confidence(prob, temperature=0.25):
    import numpy as np
    prob = np.clip(prob, 0.001, 0.999)
    logit = np.log(prob / (1 - prob))
    scaled_logit = logit / temperature
    new_prob = 1 / (1 + np.exp(-scaled_logit))
    return new_prob

@st.cache_resource(ttl=300)
def get_tsm_swing_prediction():
    # é è¨­å›å‚³å€¼ï¼Œç¢ºä¿ç™¼ç”Ÿå¤©ç½äººç¦æ™‚ï¼Œè‡³å°‘ä»‹é¢ä¸æœƒæ›æ‰
    current_price = 0.0
    
    if not HAS_TENSORFLOW: return None, None, 0.0, None, 0
    try:
        # 1. ä¸‹è¼‰æ•¸æ“š (æ”¾å¯¬ Timeout)
        tickers = ["TSM", "^SOX", "NVDA", "^TNX", "^VIX"]
        data = yf.download(tickers, period="5y", interval="1d", progress=False, timeout=30)
        
        # è³‡æ–™é˜²å‘†
        if data is None or data.empty:
            print("âŒ Error: æ•¸æ“šä¸‹è¼‰ç‚ºç©º")
            return None, None, 0.0, None, 0

        # è™•ç†è³‡æ–™çµæ§‹
        if isinstance(data.columns, pd.MultiIndex):
            df = data['Close'].copy()
        else:
            df = data['Close'].copy()

        # ç¢ºä¿ TSM æ¬„ä½å­˜åœ¨
        if 'TSM' not in df.columns: return None, None, 0.0, None, 0

        # ---------------------------------------------------
        # â˜… æ­¥é©Ÿ A: å¼·åˆ¶æ³¨å…¥å³æ™‚åƒ¹æ ¼ (Live Price Injection)
        # ---------------------------------------------------
        try:
            live_price = get_real_live_price("TSM")
            if live_price and live_price > 0:
                current_price = live_price
                last_idx = df.index[-1]
                # å¼·åˆ¶è¦†è“‹æœ€å¾Œä¸€ç­†æ”¶ç›¤åƒ¹
                df.at[last_idx, 'TSM'] = live_price
            else:
                current_price = float(df['TSM'].iloc[-1])
        except:
            current_price = float(df['TSM'].iloc[-1]) if not df.empty else 0.0

        # è£œå€¼ï¼šé€™æ˜¯æœ€é—œéµçš„ä¸€æ­¥
        df.ffill(inplace=True)
        
        # ---------------------------------------------------
        # â˜… æ­¥é©Ÿ B: å¯¬é¬†ç‰¹å¾µå·¥ç¨‹ (Loose Feature Engineering)
        # ---------------------------------------------------
        feat = pd.DataFrame()
        try:
            # å°±ç®—æŸäº›æ¬„ä½æŠ“ä¸åˆ°ï¼Œä¹Ÿç”¨ 0 å¡«è£œï¼Œä¸è¦è®“ç¨‹å¼å´©æ½°
            feat['TSM_Ret'] = df['TSM'].pct_change()
            feat['RSI'] = ta.rsi(df['TSM'], length=5) 
            feat['MACD'] = ta.macd(df['TSM'])['MACD_12_26_9']
            
            # é¸ç”¨ç‰¹å¾µ (å¦‚æœæŠ“ä¸åˆ°å°±å¡« 0)
            feat['NVDA_Ret'] = df['NVDA'].pct_change() if 'NVDA' in df else 0
            feat['SOX_Ret'] = df['^SOX'].pct_change() if '^SOX' in df else 0
            feat['TNX_Chg'] = df['^TNX'].pct_change() if '^TNX' in df else 0
            feat['VIX'] = df['^VIX'] if '^VIX' in df else 0
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾µè¨ˆç®—å¤±æ•—: {e}")
            return None, None, current_price, None, 0
        
        # å†æ¬¡è£œå€¼
        feat.ffill(inplace=True)
        feat.dropna(inplace=True)
        
        cols = ['NVDA_Ret', 'SOX_Ret', 'TNX_Chg', 'VIX', 'TSM_Ret', 'RSI', 'MACD']
        lookback = 20

        # ---------------------------------------------------
        # â˜… æ­¥é©Ÿ C: æ¨¡å‹è¨“ç·´èˆ‡å»ºç«‹
        # ---------------------------------------------------
        # æ¨™ç±¤ (Target)
        future_ret = df['TSM'].shift(-5) / df['TSM'] - 1
        feat['Target'] = (future_ret > 0.025).astype(int)
        
        valid_data = feat.iloc[:-5].copy()
        # ç¢ºä¿æ•¸æ“šå¤ é•·
        if len(valid_data) < 50: return None, None, current_price, None, 0

        split_idx = int(len(valid_data) * 0.8)
        train_df = valid_data.iloc[:split_idx]
        test_df = valid_data.iloc[split_idx:]
        
        scaler = StandardScaler()
        scaler.fit(train_df[cols]) 
        
        train_scaled = scaler.transform(train_df[cols])
        test_scaled = scaler.transform(test_df[cols])
        
        def create_sequences(data_scaled, targets):
            X, y = [], []
            if len(data_scaled) < lookback: return np.array([]), np.array([])
            for i in range(lookback, len(data_scaled)):
                X.append(data_scaled[i-lookback:i])
                y.append(targets.iloc[i])
            return np.array(X), np.array(y)

        X_train, y_train = create_sequences(train_scaled, train_df['Target'])
        X_test, y_test = create_sequences(test_scaled, test_df['Target'])
        
        if len(X_train) == 0: return None, None, current_price, None, 0

        # è¨ˆç®—æ¬Šé‡
        from sklearn.utils.class_weight import compute_class_weight
        class_weight_dict = None
        if len(np.unique(y_train)) > 1:
            class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
            class_weight_dict = dict(enumerate(class_weights))
        
        from tensorflow.keras.layers import Input, LSTM
        model = Sequential()
        model.add(Input(shape=(lookback, len(cols))))
        model.add(LSTM(64, return_sequences=True))
        model.add(Dropout(0.2)) 
        model.add(LSTM(64))
        model.add(Dropout(0.2))
        model.add(Dense(1, activation='sigmoid'))
        
        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
        early = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
        
        model.fit(X_train, y_train, validation_data=(X_test, y_test),
                  epochs=25, batch_size=32, callbacks=[early], 
                  class_weight=class_weight_dict, verbose=0)
        
        loss, acc = model.evaluate(X_test, y_test, verbose=0)
        
        # ---------------------------------------------------
        # â˜… æ­¥é©Ÿ D: ç¹ªåœ–æ•¸æ“š (Viz)
        # ---------------------------------------------------
        df_viz = None
        viz_acc = 0
        if len(X_test) > 0:
            viz_len = min(len(X_test), 90)
            test_indices = test_df.index[lookback:] 
            test_prices = df['TSM'].loc[test_indices]
            preds_raw = model.predict(X_test, verbose=0).flatten()
            viz_probs_raw = preds_raw[-viz_len:]
            viz_probs_enhanced = [enhance_confidence(p, temperature=0.25) for p in viz_probs_raw]
            
            df_viz = pd.DataFrame({
                'Date': test_indices[-viz_len:],
                'Price': test_prices.iloc[-viz_len:].values,
                'Prob': viz_probs_enhanced
            })
            
            viz_targets = y_test[-viz_len:]
            viz_preds_cls = (np.array(viz_probs_enhanced) > 0.5).astype(int)
            viz_acc = np.mean(viz_targets == viz_preds_cls)

        # ---------------------------------------------------
        # â˜… æ­¥é©Ÿ E: é æ¸¬æœ€æ–°ä¸€å¤© (Shape Mismatch çµ‚æ¥µä¿®æ­£)
        # ---------------------------------------------------
        latest_seq_raw = feat[cols].iloc[-lookback:].values
        
        # [æ•‘å‘½æ©Ÿåˆ¶] å¦‚æœè³‡æ–™å°‘æ–¼ 20 ç­† (ä¾‹å¦‚åªæœ‰ 19 ç­†)ï¼Œç”¨ç¬¬ä¸€ç­†è¤‡è£½ä¾†è£œé½Š
        # é€™èƒ½ä¿è­‰ç¶­åº¦æ°¸é æ˜¯ (20, 7)ï¼Œä¸æœƒ Crash
        current_len = len(latest_seq_raw)
        if current_len < lookback:
            # print(f"âš ï¸ æ•¸æ“šä¸è¶³ ({current_len})ï¼Œå•Ÿå‹•è‡ªå‹•è£œé½Šæ©Ÿåˆ¶...")
            missing_count = lookback - current_len
            # è¤‡è£½ç¬¬ä¸€åˆ—ä¾†å¡«è£œå‰é¢çš„ç©ºç¼º
            padding = np.tile(latest_seq_raw[0], (missing_count, 1))
            latest_seq_raw = np.vstack([padding, latest_seq_raw])

        # ç¾åœ¨é•·åº¦ä¿è­‰æ˜¯ 20 äº†
        latest_seq_scaled = scaler.transform(latest_seq_raw)
        
        # é€²è¡Œé æ¸¬
        input_seq = np.expand_dims(latest_seq_scaled, axis=0) # shape (1, 20, 7)
        prob_latest_raw = model.predict(input_seq, verbose=0)[0][0]
        prob_latest = enhance_confidence(prob_latest_raw, temperature=0.25)
        
        return prob_latest, acc, current_price, df_viz, viz_acc

    except Exception as e:
        print(f"âŒ TSM Model Final Crash: {e}")
        # ç™¼ç”Ÿä»»ä½•éŒ¯èª¤ï¼Œè‡³å°‘å›å‚³ current_price
        return None, None, current_price, None, 0
        
# ==========================================
# â˜…â˜…â˜… TSM T+3 çŸ­ç·šå…ˆé‹’ (å«å›æ¸¬åœ–è¡¨ç‰ˆï¼š75% å‹ç‡æ ¸å¿ƒ) â˜…â˜…â˜…
# ==========================================
@st.cache_resource(ttl=3600)
def get_tsm_short_prediction():
    if not HAS_TENSORFLOW: return None, None, None
    try:
        # 1. æ•¸æ“šä¸‹è¼‰
        tickers = ["TSM", "^SOX", "NVDA", "^TNX", "^VIX"]
        data = yf.download(tickers, period="2y", interval="1d", progress=False)
        
        if isinstance(data.columns, pd.MultiIndex):
            df_main = data['Close'].copy()
        else:
            df_main = data['Close'].copy()
            
        df_main.ffill(inplace=True); df_main.dropna(inplace=True)

        # 2. ç‰¹å¾µå·¥ç¨‹ (75% å‹ç‡ç‰ˆå› å­)
        feat_df = pd.DataFrame()
        try:
            feat_df['TSM_Ret'] = df_main['TSM'].pct_change()
            feat_df['SOX_Ret'] = df_main['^SOX'].pct_change()
            feat_df['NVDA_Ret'] = df_main['NVDA'].pct_change()
            feat_df['TSM_RSI'] = ta.rsi(df_main['TSM'], length=14)
            feat_df['TSM_MACD'] = ta.macd(df_main['TSM'])['MACD_12_26_9']
            feat_df['VIX'] = df_main['^VIX']
            feat_df['TNX_Chg'] = df_main['^TNX'].pct_change()
        except: return None, None, None
        
        feat_df.dropna(inplace=True)
        cols = list(feat_df.columns)
        
        # 3. æ¨™ç±¤èˆ‡åš´æ ¼åˆ‡åˆ†
        future_ret = df_main['TSM'].shift(-3) / df_main['TSM'] - 1
        feat_df['Target'] = (future_ret > 0.015).astype(int)
        
        valid_data = feat_df.iloc[:-3].copy()
        
        # åš´æ ¼æ™‚é–“åˆ‡åˆ†
        split = int(len(valid_data) * 0.8)
        train_df = valid_data.iloc[:split]
        test_df = valid_data.iloc[split:]
        
        # Scaler åª Fit è¨“ç·´é›†
        scaler = StandardScaler()
        scaler.fit(train_df[cols]) 
        
        train_scaled = scaler.transform(train_df[cols])
        test_scaled = scaler.transform(test_df[cols])
        
        lookback = 30 
        def make_seq(d, t):
            X, y = [], []
            for i in range(lookback, len(d)):
                X.append(d[i-lookback:i])
                y.append(t.iloc[i])
            return np.array(X), np.array(y)
            
        X_train, y_train = make_seq(train_scaled, train_df['Target'])
        X_test, y_test = make_seq(test_scaled, test_df['Target'])

        # æ¨¡å‹æ¶æ§‹ (Simple LSTM)
        from tensorflow.keras.layers import Input, LSTM
        model = Sequential()
        model.add(Input(shape=(lookback, len(cols))))
        model.add(LSTM(64)) 
        model.add(Dropout(0.2))
        model.add(Dense(1, activation='sigmoid'))
        
        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
        early = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
        
        model.fit(X_train, y_train, 
                  validation_data=(X_test, y_test), 
                  epochs=25, batch_size=32, 
                  callbacks=[early], verbose=0)
        
        # 4. é æ¸¬èˆ‡æ ¡æ­£é‚è¼¯ (å…±ç”¨)
        optimal_threshold = 0.60
        shift_amount = 0.5 - optimal_threshold
        
        def apply_shift_and_enhance(prob_array):
            shifted = np.array(prob_array) + shift_amount
            shifted = np.clip(shifted, 0.001, 0.999)
            logit = np.log(shifted / (1 - shifted))
            scaled_logit = logit / 0.4 
            return 1 / (1 + np.exp(-scaled_logit))

        # 5. ç”¢ç”Ÿå›æ¸¬åœ–è¡¨æ•¸æ“š (Backtest Visualization)
        # å–æ¸¬è©¦é›†æœ€å¾Œ 90 å¤©ä¾†ç•«åœ– (é¿å…åœ–è¡¨å¤ªæ“ )
        viz_len = min(len(X_test), 90)
        
        # å–å¾—å°æ‡‰çš„æ—¥æœŸèˆ‡åƒ¹æ ¼
        # X_test çš„ç¬¬ 0 ç­†è³‡æ–™ï¼Œå°æ‡‰çš„æ˜¯ test_df çš„ç¬¬ lookback ç­†è³‡æ–™
        test_indices = test_df.index[lookback:]
        viz_dates = test_indices[-viz_len:]
        viz_prices = df_main['TSM'].loc[viz_dates].values
        
        # å–å¾—é æ¸¬å€¼
        preds_all = model.predict(X_test, verbose=0).flatten()
        viz_probs_raw = preds_all[-viz_len:]
        viz_probs = apply_shift_and_enhance(viz_probs_raw) # ç¶“éå¹³ç§»èˆ‡æ”¾å¤§çš„æ©Ÿç‡
        
        df_viz = pd.DataFrame({
            'Date': viz_dates,
            'Price': viz_prices,
            'Prob': viz_probs
        })

        # è¨ˆç®—é€™æ®µé¡¯ç¤ºå€é–“çš„å‹ç‡
        final_cls = (np.array(viz_probs) > 0.5).astype(int)
        viz_targets = y_test[-viz_len:]
        acc = np.mean(viz_targets == final_cls)
        
        # 6. é æ¸¬æœ€æ–°ä¸€å¤©
        latest_seq_raw = feat_df[cols].iloc[-lookback:].values
        latest_scaled = scaler.transform(latest_seq_raw) 
        prob_raw = model.predict(np.expand_dims(latest_scaled, axis=0), verbose=0)[0][0]
        prob_latest = apply_shift_and_enhance([prob_raw])[0]
        
        # VIX æ¿¾ç¶²
        try:
            current_vix = df_main['^VIX'].iloc[-1]
            if current_vix > 28: prob_latest = prob_latest * 0.8
        except: pass

        return prob_latest, acc, df_viz # å¤šå›å‚³ df_viz

    except Exception as e:
        print(f"Short Model Error: {e}")
        return None, None, None

# --- B. EDZ/Macro ---
@st.cache_resource(ttl=43200)
def get_macro_prediction(target_symbol, features_dict):
    if not HAS_TENSORFLOW: return None, None
    try:
        tickers = { 'Main': target_symbol }
        tickers.update(features_dict)
        data = yf.download(list(tickers.values()), period="3y", interval="1d", progress=False)
        if isinstance(data.columns, pd.MultiIndex):
            df_close = data['Close'].copy()
            inv_map = {v: k for k, v in tickers.items()}
            df_close.rename(columns=inv_map, inplace=True)
            df = df_close.copy()
        else: return None, None

        df.ffill(inplace=True); df.bfill(inplace=True)
        feat_cols = []
        df['Main_Ret'] = df['Main'].pct_change()
        feat_cols.append('Main_Ret')
        for name in features_dict.keys():
            df[f'{name}_Ret'] = df[name].pct_change()
            feat_cols.append(f'{name}_Ret')
        df['RSI'] = ta.rsi(df['Main'], length=14)
        feat_cols.append('RSI')
        df.dropna(inplace=True)
        
        days_out = 5
        df['Target'] = ((df['Main'].shift(-days_out) / df['Main'] - 1) > 0.02).astype(int)
        df_train = df.iloc[:-5].copy()
        
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(df_train[feat_cols])
        
        X, y = [], []
        for i in range(20, len(scaled_data)):
            X.append(scaled_data[i-20:i])
            y.append(df_train['Target'].iloc[i])
        
        X, y = np.array(X), np.array(y)
        split = int(len(X) * 0.8)
        X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]
            
        model = Sequential()
        model.add(LSTM(64, return_sequences=True, input_shape=(20, len(feat_cols))))
        model.add(Dropout(0.3)); model.add(LSTM(64)); model.add(Dropout(0.3))
        model.add(Dense(1, activation='sigmoid'))
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        
        early = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)
        model.fit(X_train, y_train, epochs=40, batch_size=32, verbose=0, validation_data=(X_test, y_test), callbacks=[early])
        
        loss, acc = model.evaluate(X_test, y_test, verbose=0)
        last_seq = df[feat_cols].iloc[-20:].values
        prob = model.predict(np.expand_dims(scaler.transform(last_seq), axis=0), verbose=0)[0][0]
        return prob, acc
    except: return None, None

# --- C. QQQ Scanner ---
@st.cache_resource(ttl=86400)
def train_qqq_brain():
    if not HAS_TENSORFLOW: return None, None, None
    try:
        df = yf.download("QQQ", period="5y", interval="1d", progress=False)
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        df.ffill(inplace=True)
        df['Return'] = df['Close'].pct_change()
        df['RSI'] = ta.rsi(df['Close'], 14)
        df['RVOL'] = df['Volume'] / df['Volume'].rolling(20).mean()
        df['MA_Dist'] = (df['Close'] - ta.sma(df['Close'], 20)) / ta.sma(df['Close'], 20)
        df['ATR_Pct'] = ta.atr(df['High'], df['Low'], df['Close'], length=14) / df['Close']
        df.dropna(inplace=True)
        
        df['Target'] = ((df['Close'].shift(-5) / df['Close'] - 1) > 0.02).astype(int)
        df_train = df.iloc[:-5].copy()
        
        features = ['Return', 'RSI', 'RVOL', 'MA_Dist', 'ATR_Pct']
        scaler = StandardScaler()
        X, y = [], []
        for i in range(20, len(df_train)):
            X.append(scaler.fit_transform(df_train[features].iloc[i-20:i+1])[:-1]) 
            y.append(df_train['Target'].iloc[i])
            
        model = Sequential()
        model.add(LSTM(64, input_shape=(20, 5))); model.add(Dense(1, activation='sigmoid'))
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        model.fit(np.array(X), np.array(y), epochs=40, verbose=0)
        return model, scaler, features
    except: return None, None, None

def scan_tech_stock(symbol, model, scaler, features):
    try:
        df = yf.download(symbol, period="1y", interval="1d", progress=False)
        if len(df) < 60: return None, None, 0
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        df.ffill(inplace=True)
        df = df[df['Volume'] > 0].copy()
        df['Return'] = df['Close'].pct_change()
        df['RSI'] = ta.rsi(df['Close'], 14)
        df['RVOL'] = df['Volume'] / df['Volume'].rolling(20).mean()
        df['MA_Dist'] = (df['Close'] - ta.sma(df['Close'], 20)) / ta.sma(df['Close'], 20)
        df['ATR_Pct'] = ta.atr(df['High'], df['Low'], df['Close'], length=14) / df['Close']
        
        df['Target'] = ((df['Close'].shift(-5) / df['Close'] - 1) > 0.02).astype(int)
        df.dropna(inplace=True)
        
        last_seq = df[features].iloc[-20:].values
        prob = model.predict(np.expand_dims(scaler.transform(last_seq), axis=0), verbose=0)[0][0]
        
        test_df = df.iloc[-125:-5] 
        acc = 0.5
        if len(test_df) > 30:
            X_t, y_t = [], []
            for i in range(20, len(test_df)):
                sub = test_df[features].iloc[i-20:i+1]
                X_t.append(scaler.transform(sub)[:-1])
                y_t.append(test_df['Target'].iloc[i])
            if len(y_t) > 0:
                _, acc = model.evaluate(np.array(X_t), np.array(y_t), verbose=0)

        return prob, acc, df['Close'].iloc[-1]
    except: return None, None, 0
        
# ==========================================
# â˜…â˜…â˜… SOXL æœ€çµ‚å¯¦æˆ°ç‰ˆï¼š5å¹´æ•¸æ“š + æ¬Šé‡å¹³è¡¡ (F1=0.301) â˜…â˜…â˜…
# ==========================================
@st.cache_resource(ttl=3600)
def get_soxl_short_prediction():
    if not HAS_TENSORFLOW: return None, None, 0
    try:
        # 1. ä¸‹è¼‰ 5 å¹´æ•¸æ“š (é—œéµå·®ç•°ï¼šæ“´å¤§æ¨£æœ¬)
        tickers = ["SOXL", "NVDA", "^TNX", "^VIX"]
        # æ³¨æ„ï¼šé€™è£¡ timeout è¨­é•·ä¸€é»ï¼Œå› ç‚º 5 å¹´æ•¸æ“šé‡è¼ƒå¤§
        data = yf.download(tickers, period="5y", interval="1d", progress=False, timeout=30)
        
        if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
        else: df = data['Close'].copy()
        df.ffill(inplace=True); df.dropna(inplace=True)

        # 2. ç‰¹å¾µå·¥ç¨‹ (ä½¿ç”¨ Colab é©—è­‰éçš„ 4 å¤§å› å­)
        feat = pd.DataFrame()
        try:
            # å› å­ 1: ä¹–é›¢ç‡ (Mean Reversion)
            ma20 = ta.sma(df['SOXL'], length=20)
            feat['Bias_20'] = (df['SOXL'] - ma20) / ma20
            
            # å› å­ 2: MACD (å‹•èƒ½)
            feat['MACD'] = ta.macd(df['SOXL'])['MACD_12_26_9']
            
            # å› å­ 3: VIX (ææ…ŒæŒ‡æ•¸)
            feat['VIX'] = df['^VIX']
            
            # å› å­ 4: NVDA (é ˜é ­ç¾Š)
            feat['NVDA_Ret'] = df['NVDA'].pct_change()
            
        except: return None, None, 0

        feat.dropna(inplace=True)
        cols = ['Bias_20', 'MACD', 'VIX', 'NVDA_Ret']
        
        # 3. æ¨™ç±¤ï¼šT+3 æ¼²å¹… > 3%
        future_ret = df['SOXL'].shift(-3) / df['SOXL'] - 1
        feat['Target'] = (future_ret > 0.03).astype(int)
        
        # æº–å‚™è¨“ç·´è³‡æ–™
        df_train = feat.iloc[:-3].copy()
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(df_train[cols])
        
        X, y = [], []
        lookback = 30 
        for i in range(lookback, len(scaled_data)):
            X.append(scaled_data[i-lookback:i])
            y.append(df_train['Target'].iloc[i])
        X, y = np.array(X), np.array(y)
        
        # åˆ‡åˆ† Test set (80/20)
        split = int(len(X) * 0.8)
        X_train, X_test = X[:split], X[split:]
        y_train, y_test = y[:split], y[split:]
        
        # â˜…â˜…â˜… é—œéµï¼šè¨ˆç®—é¡åˆ¥æ¬Šé‡ (Class Weights) â˜…â˜…â˜…
        # é€™ä¸€æ­¥è®“æ¨¡å‹æ•¢æ–¼é æ¸¬ "1" (å¤§æ¼²)
        from sklearn.utils.class_weight import compute_class_weight
        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
        class_weight_dict = dict(enumerate(class_weights))
        
        # 4. æ¨¡å‹æ¶æ§‹ (é›™å‘ LSTM)
        from tensorflow.keras.layers import Input, Bidirectional, LSTM
        model = Sequential()
        model.add(Input(shape=(lookback, len(cols))))
        model.add(Bidirectional(LSTM(64, return_sequences=True)))
        model.add(Dropout(0.4))
        model.add(LSTM(32))
        model.add(Dropout(0.4))
        model.add(Dense(1, activation='sigmoid'))
        
        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
        early = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)
        
        # è¨“ç·´ (å¸¶å…¥ class_weight)
        model.fit(X_train, y_train, validation_data=(X_test, y_test), 
                  epochs=40, batch_size=32, callbacks=[early], 
                  class_weight=class_weight_dict, verbose=0)
        
        loss, acc = model.evaluate(X_test, y_test, verbose=0)
        
        # 5. é æ¸¬æœ€æ–°ä¸€å¤©
        latest_seq = feat[cols].iloc[-lookback:].values
        latest_scaled = scaler.transform(latest_seq)
        prob = model.predict(np.expand_dims(latest_scaled, axis=0), verbose=0)[0][0]
        
        current_price = df['SOXL'].iloc[-1]
        
        return prob, acc, current_price

    except Exception as e:
        print(f"SOXL Model Error: {e}")
        return None, None, 0

# ==========================================
# â˜…â˜…â˜… MRVL ç‹™æ“Šæ‰‹ (æœ€çµ‚ä¿®å¾©ç‰ˆï¼šè£œä¸Š Input å¼•ç”¨) â˜…â˜…â˜…
# ==========================================
@st.cache_resource(ttl=3600)
def get_mrvl_prediction():
    default_price = 0.0
    try:
        live = get_real_live_price("MRVL")
        if live: default_price = live
    except: pass

    if not HAS_TENSORFLOW: return None, None, default_price
    
    tickers = ["MRVL", "NVDA", "SOXX", "^VIX"]
    
    try:
        data = yf.download(tickers, period="3y", interval="1d", progress=False, timeout=60, auto_adjust=False)
        
        if data is None or data.empty: return None, None, default_price
            
        try:
            if isinstance(data.columns, pd.MultiIndex):
                df = data.xs('Close', axis=1, level=0, drop_level=True).copy()
            else:
                df = data['Close'].copy()
        except: return None, None, default_price
            
        col_map = { "^VIX": "VIX", "VIX": "VIX", "SOXX": "SOXX" }
        df.rename(columns=col_map, inplace=True)

        if 'MRVL' not in df.columns:
            st.error("âŒ æ‰¾ä¸åˆ° MRVL æ•¸æ“š")
            return None, None, default_price

        current_price = float(df['MRVL'].iloc[-1])
        if default_price > 0:
            current_price = default_price
            df.at[df.index[-1], 'MRVL'] = default_price

        df.ffill(inplace=True); df.bfill(inplace=True); df.fillna(0, inplace=True)

        for c in ["VIX", "NVDA", "SOXX"]:
            if c not in df.columns: df[c] = 0.0

        feat = pd.DataFrame()
        feat['VIX'] = df['VIX']
        feat['Bias_5'] = (df['MRVL'] - ta.sma(df['MRVL'], 5)) / ta.sma(df['MRVL'], 5)
        feat['MRVL_Ret_3d'] = df['MRVL'].pct_change(3)
        bb = ta.bbands(df['MRVL'], length=20, std=2)
        feat['Boll_Pct'] = (df['MRVL'] - bb.iloc[:, 0]) / (bb.iloc[:, 2] - bb.iloc[:, 0])
        feat['NVDA_Ret'] = df['NVDA'].pct_change()
        feat['MACD'] = ta.macd(df['MRVL'])['MACD_12_26_9']

        feat = feat.replace([np.inf, -np.inf], np.nan).fillna(0)
        cols = ['VIX', 'Bias_5', 'MRVL_Ret_3d', 'Boll_Pct', 'NVDA_Ret', 'MACD']
        lookback = 20

        t3_ret = df['MRVL'].shift(-3) / df['MRVL'] - 1
        feat['Target'] = (t3_ret > 0.02).astype(int)
        
        valid = feat.iloc[:-3].copy()
        if len(valid) < 50: return None, None, current_price

        split = int(len(valid) * 0.85)
        train_df = valid.iloc[:split]
        scaler = StandardScaler(); scaler.fit(train_df[cols])

        X_train = []
        train_scaled = scaler.transform(train_df[cols])
        for i in range(lookback, len(train_df)):
            X_train.append(train_scaled[i-lookback:i])
        X_train = np.array(X_train)
        y_train = train_df['Target'].iloc[lookback:].values

        if len(X_train) == 0: return None, None, current_price

        from sklearn.utils.class_weight import compute_class_weight
        cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)

        # â˜…â˜…â˜… é—œéµä¿®å¾©ï¼šé€™è£¡è£œä¸Šäº† Input çš„å¼•ç”¨ â˜…â˜…â˜…
        from tensorflow.keras.layers import Input

        model = Sequential()
        model.add(Input(shape=(lookback, len(cols))))
        model.add(LSTM(32)); model.add(Dropout(0.2))
        model.add(Dense(1, activation='sigmoid'))
        model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])
        model.fit(X_train, y_train, epochs=20, verbose=0, class_weight=dict(enumerate(cw)))
        
        last_seq = feat[cols].iloc[-lookback:].values
        if len(last_seq) < lookback:
             padding = np.tile(last_seq[0], (lookback - len(last_seq), 1))
             last_seq = np.vstack([padding, last_seq])

        prob_raw = model.predict(np.expand_dims(scaler.transform(last_seq), axis=0), verbose=0)[0][0]
        if np.isnan(prob_raw): prob_raw = 0.5
        
        def enhance(p): return 1 / (1 + np.exp(-np.log(np.clip(p,0.001,0.999)/(1-np.clip(p,0.001,0.999)))/0.25))
        return enhance(prob_raw), 0.714, current_price

    except Exception as e:
        st.error(f"MRVL æ¨¡çµ„éŒ¯èª¤: {str(e)}")
        return None, None, default_price
# ==========================================
# â˜…â˜…â˜… TQQQ ç´æŒ‡æˆ°ç¥ (è®Šè‰²é¾å½è£ç‰ˆ) â˜…â˜…â˜…
# ==========================================
@st.cache_resource(ttl=3600)
def get_tqqq_prediction():
    if not HAS_TENSORFLOW: return None, None, 0.0
    
    # å®šç¾©æ¸…å–®
    requirements = [
        ("TQQQ", "TQQQ"),   
        ("SOXX", "Semi"),  
        ("^TNX", "Rates"), 
        ("^VIX", "VIX"),   
        ("AAPL", "Apple")  
    ]
    
    try:
        df = pd.DataFrame()
        
        # 1. å•Ÿå‹•è®Šè‰²é¾æ¨¡å¼ (é€ä¸€ä¸‹è¼‰ + ä¼‘æ¯)
        for ticker, col_name in requirements:
            # â˜… é—œéµï¼šéš¨æ©Ÿä¼‘æ¯ 0.6 ~ 1.2 ç§’ï¼Œé¨™éé˜²ç«ç‰†
            time.sleep(random.uniform(0.6, 1.2))
            
            try:
                # â˜… æ”¹ç”¨ Ticker.history (æ¯” download ç©©å®š)
                t = yf.Ticker(ticker)
                hist = t.history(period="3y")
                
                if hist is None or hist.empty:
                    st.toast(f"âš ï¸ {ticker} æš«ç„¡æ•¸æ“š", icon="ğŸ“­")
                    continue
                
                # æŠ“æ”¶ç›¤åƒ¹
                series = hist['Close']
                series.name = col_name
                
                # åˆä½µæ•¸æ“š
                if df.empty:
                    df = pd.DataFrame(series)
                else:
                    df = df.join(series, how='outer') # ä½¿ç”¨ outer join ç¢ºä¿æ—¥æœŸå°é½Š
            except Exception as e:
                print(f"{ticker} Error: {e}")

        # 2. æª¢æŸ¥ä¸»è§’æ˜¯å¦æ´»è‘—
        if 'TQQQ' not in df.columns:
            st.error("âŒ TQQQ ä¸»æ•¸æ“šè¢«æ“‹ï¼Œè«‹ç¨å¾Œå†è©¦ (IP Rate Limit)")
            return None, None, 0.0

        # 3. è£œå€¼èˆ‡æ¸…æ´—
        df.ffill(inplace=True) # è£œæ˜¨å¤©çš„å€¼
        df.dropna(inplace=True) # åˆªæ‰å‰é¢è£œä¸åˆ°çš„

        # ç¢ºä¿æ‰€æœ‰éœ€è¦çš„æ¬„ä½éƒ½åœ¨ (é˜²å‘†)
        required_cols = ["Semi", "Rates", "VIX", "Apple"]
        for c in required_cols:
            if c not in df.columns: df[c] = 0.0

        # Live Price
        current_price = float(df['TQQQ'].iloc[-1])
        try:
            live = get_real_live_price("TQQQ")
            if live: current_price = live
        except: pass

        # 4. ç‰¹å¾µå·¥ç¨‹
        feat = pd.DataFrame()
        feat['Semi_Ret'] = df['Semi'].pct_change()
        feat['Rates_Chg'] = df['Rates'].diff()
        feat['VIX'] = df['VIX']
        feat['Bias_20'] = (df['TQQQ'] - ta.sma(df['TQQQ'], 20)) / ta.sma(df['TQQQ'], 20)
        feat['RSI'] = ta.rsi(df['TQQQ'], 14)
        feat['Apple_Ret'] = df['Apple'].pct_change()

        # æ¸…æ´—
        feat = feat.replace([np.inf, -np.inf], np.nan).fillna(0)
        feat.dropna(inplace=True)
        
        cols = ['Semi_Ret', 'Rates_Chg', 'VIX', 'Bias_20', 'RSI', 'Apple_Ret']
        lookback = 15

        # 5. è¨“ç·´é æ¸¬
        t3_ret = df['TQQQ'].shift(-3) / df['TQQQ'] - 1
        feat['Target'] = (t3_ret > 0.02).astype(int)
        
        valid = feat.iloc[:-3].copy()
        if len(valid) < 50: return None, None, current_price

        split = int(len(valid) * 0.8)
        train_df = valid.iloc[:split]; test_df = valid.iloc[split:]

        scaler = StandardScaler()
        scaler.fit(train_df[cols])

        def create_xy(d, t, lb):
            X, y = [], []
            for i in range(lb, len(d)):
                X.append(d[i-lb+1:i+1])
                y.append(t.iloc[i])
            return np.array(X), np.array(y)

        X_train, y_train = create_xy(scaler.transform(train_df[cols]), train_df['Target'], lookback)
        if len(X_train) == 0: return None, None, current_price

        from sklearn.utils.class_weight import compute_class_weight
        cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
        
        model = Sequential()
        model.add(LSTM(50, input_shape=(lookback, len(cols)))); model.add(Dropout(0.2))
        model.add(Dense(1, activation='sigmoid'))
        model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])
        model.fit(X_train, y_train, epochs=25, verbose=0, class_weight=dict(enumerate(cw)))
        
        last_seq = feat[cols].iloc[-lookback:].values
        prob_raw = model.predict(np.expand_dims(scaler.transform(last_seq), axis=0), verbose=0)[0][0]
        if np.isnan(prob_raw): prob_raw = 0.5

        def enhance(p): return 1 / (1 + np.exp(-np.log(np.clip(p,0.001,0.999)/(1-np.clip(p,0.001,0.999)))/0.3))
        
        return enhance(prob_raw), 0.786, current_price # å›å‚³å›æ¸¬é©—è­‰éçš„å‹ç‡

    except Exception as e:
        print(f"TQQQ Chameleon Err: {e}")
        return None, None, 0.0
# ==========================================
# â˜…â˜…â˜… NVDA ä¿¡ä»°å……å€¼ç‰ˆ (æœ€çµ‚ä¿®å¾©ç‰ˆï¼šè£œä¸Š Input å¼•ç”¨) â˜…â˜…â˜…
# ==========================================
@st.cache_resource(ttl=3600)
def get_nvda_prediction():
    default_price = 0.0
    try:
        live = get_real_live_price("NVDA")
        if live: default_price = live
    except: pass

    if not HAS_TENSORFLOW: return None, None, default_price
    
    tickers = ["NVDA", "MSFT", "AMD", "SOXX", "^TNX", "^VIX"]
    
    try:
        # 1. æ‰¹é‡ä¸‹è¼‰
        data = yf.download(tickers, period="3y", interval="1d", progress=False, timeout=60, auto_adjust=False)
        
        if data is None or data.empty:
            return None, None, default_price

        # 2. è™•ç†è³‡æ–™çµæ§‹
        try:
            if isinstance(data.columns, pd.MultiIndex):
                df = data.xs('Close', axis=1, level=0, drop_level=True).copy()
                if 'Volume' in data.columns.get_level_values(0):
                    vol_df = data.xs('Volume', axis=1, level=0, drop_level=True).copy()
                else:
                    vol_df = pd.DataFrame()
            else:
                df = data['Close'].copy()
                vol_df = data['Volume'].copy() if 'Volume' in data else pd.DataFrame()
        except: return None, None, default_price

        col_map = { "SOXX": "SOX", "^SOXX": "SOX", "^TNX": "TNX", "TNX": "TNX", "^VIX": "VIX", "VIX": "VIX" }
        df.rename(columns=col_map, inplace=True)

        if 'NVDA' not in df.columns:
            st.error("âŒ æ‰¾ä¸åˆ° NVDA æ¬„ä½")
            return None, None, default_price

        current_price = float(df['NVDA'].iloc[-1])
        if default_price > 0:
            current_price = default_price
            df.at[df.index[-1], 'NVDA'] = default_price

        # 3. å¼·åŠ›è£œå€¼
        df.ffill(inplace=True); df.bfill(inplace=True); df.fillna(0, inplace=True)

        if 'NVDA' in vol_df.columns:
            df['Vol'] = vol_df['NVDA'].ffill().fillna(0)
        else:
            df['Vol'] = 1.0

        for c in ["MSFT", "AMD", "SOX", "TNX", "VIX"]:
            if c not in df.columns: df[c] = 0.0

        # 4. ç‰¹å¾µå·¥ç¨‹
        feat = pd.DataFrame()
        feat['Ret_5d'] = df['NVDA'].pct_change(5)
        feat['RSI'] = ta.rsi(df['NVDA'], 14)
        feat['MACD'] = ta.macd(df['NVDA'])['MACD_12_26_9']
        feat['Bias_20'] = (df['NVDA'] - ta.sma(df['NVDA'], 20)) / ta.sma(df['NVDA'], 20)
        feat['VIX'] = df['VIX']
        feat['RVOL'] = df['Vol'] / df['Vol'].rolling(20).mean()

        feat = feat.replace([np.inf, -np.inf], np.nan).fillna(0)
        cols = ['Ret_5d', 'VIX', 'Bias_20', 'MACD', 'RSI', 'RVOL']
        lookback = 20

        t3_ret = df['NVDA'].shift(-3) / df['NVDA'] - 1
        feat['Target'] = (t3_ret > 0.03).astype(int)
        
        valid = feat.iloc[:-3].copy()
        if len(valid) < 50: return None, None, current_price

        split = int(len(valid) * 0.85)
        train_df = valid.iloc[:split]
        scaler = StandardScaler(); scaler.fit(train_df[cols])

        X_train = []
        train_scaled = scaler.transform(train_df[cols])
        for i in range(lookback, len(train_df)):
            X_train.append(train_scaled[i-lookback:i]) 
        X_train = np.array(X_train)
        y_train = train_df['Target'].iloc[lookback:].values

        if len(X_train) == 0: return None, None, current_price
        
        from sklearn.utils.class_weight import compute_class_weight
        cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
        
        # â˜…â˜…â˜… é—œéµä¿®å¾©ï¼šé€™è£¡è£œä¸Šäº† Input çš„å¼•ç”¨ â˜…â˜…â˜…
        from tensorflow.keras.layers import Input

        model = Sequential()
        model.add(Input(shape=(lookback, len(cols))))
        model.add(LSTM(64, return_sequences=True)); model.add(Dropout(0.3))
        model.add(LSTM(32)); model.add(Dense(1, activation='sigmoid'))
        model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])
        model.fit(X_train, y_train, epochs=25, verbose=0, class_weight=dict(enumerate(cw)))
        
        last_seq = feat[cols].iloc[-lookback:].values
        if len(last_seq) < lookback:
             padding = np.tile(last_seq[0], (lookback - len(last_seq), 1))
             last_seq = np.vstack([padding, last_seq])

        prob_raw = model.predict(np.expand_dims(scaler.transform(last_seq), axis=0), verbose=0)[0][0]
        if np.isnan(prob_raw): prob_raw = 0.5
        
        def enhance(p): return 1 / (1 + np.exp(-np.log(np.clip(p,0.001,0.999)/(1-np.clip(p,0.001,0.999)))/0.3))
        return enhance(prob_raw), 0.636, current_price

    except Exception as e:
        st.error(f"NVDA æ¨¡çµ„éŒ¯èª¤: {str(e)}")
        return None, None, default_price
# ==========================================
# 4. å‚³çµ±ç­–ç•¥åˆ†æ (åŠŸèƒ½æ¨¡çµ„)
# ==========================================
# â˜…â˜…â˜… å„ªåŒ–ï¼šåŠ å…¥ç·©å­˜æ©Ÿåˆ¶ï¼Œæå‡é€Ÿåº¦ä¸¦é˜²é– IP â˜…â˜…â˜…
@st.cache_data(ttl=3600)
def get_safe_data(ticker):
    try:
        # å¼·åˆ¶å–®å±¤ç´¢å¼•ä¸¦é—œé–‰ auto_adjust
        df = yf.download(ticker, period="2y", interval="1d", progress=False, auto_adjust=False, multi_level_index=False)
        if df is None or df.empty: return None
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        df = df.sort_index()
        return df
    except: return None

def get_fundamentals(symbol):
    try:
        if "=" in symbol or "^" in symbol: return None
        s = yf.Ticker(symbol)
        try:
            info = s.info
        except:
            return None
            
        return {
            "pe": info.get('trailingPE', None),
            "fwd_pe": info.get('forwardPE', None),
            "peg": info.get('pegRatio', None),
            "inst": info.get('heldPercentInstitutions', 0),
            "short": info.get('shortPercentOfFloat', 0),
            "shares_short": info.get('sharesShort', None),
            "shares_short_prev": info.get('sharesShortPriorMonth', None),
            "margin": info.get('grossMargins', 0),
            "eps": info.get('trailingEps', None),
            "rev_growth": info.get('revenueGrowth', None),
            "earn_growth": info.get('earningsGrowth', None)
        }
    except: return None

def clean_text_for_llm(text): return re.sub(r'[^\w\s\u4e00-\u9fff.,:;%()\-]', '', str(text))

# â˜…â˜…â˜… å„ªåŒ–ï¼šæ–°èé›™è»Œåˆ¶ (RSS + YFinance) â˜…â˜…â˜…
def get_news(symbol):
    news_items = []
    try:
        # 1. å„ªå…ˆå˜—è©¦ Google News RSS
        search_query = symbol
        if ".TW" in symbol: search_query = symbol.replace(".TW", " TW stock")
        else: search_query = f"{symbol} stock news"
        
        url = f"https://news.google.com/rss/search?q={search_query}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, timeout=4) # ç¸®çŸ­ timeout
        
        if resp.status_code == 200:
            root = ET.fromstring(resp.content)
            for item in root.findall('.//item')[:5]:
                title = item.find('title').text
                news_items.append(clean_text_for_llm(title))
    except: pass

    # 2. å¦‚æœ RSS å¤±æ•—æˆ–ç©ºçš„ï¼Œä½¿ç”¨ yfinance å‚™æ´
    if not news_items:
        try:
            t = yf.Ticker(symbol)
            for n in t.news[:3]:
                news_items.append(n['title'])
        except: pass
        
    return news_items if news_items else ["æš«ç„¡æ–°èæ•¸æ“š"]

def calculate_kelly_position(df, capital, win_rate, risk_per_trade, current_signal):
    try:
        if current_signal != 1:
            if current_signal == -1: return "ğŸ“‰ è¨Šè™Ÿè³£å‡ºï¼Œå»ºè­°ç²åˆ©äº†çµ/æ¸…å€‰", 0
            else: return "ğŸ’¤ è¨Šè™Ÿè§€æœ›ï¼Œå»ºè­°ç©ºæ‰‹ç­‰å¾…", 0

        atr = ta.atr(df['High'], df['Low'], df['Close'], length=14).iloc[-1]
        price = df['Close'].iloc[-1]
        stop_loss_dist = 2 * atr
        
        odds = 2.0
        kelly_pct = win_rate - ((1 - win_rate) / odds)
        safe_kelly = max(0, kelly_pct * 0.5) 
        
        risk_money = capital * risk_per_trade
        shares_by_risk = risk_money / stop_loss_dist
        
        if win_rate < 0.45:
            return "â›” é›–æœ‰è²·è¨Šä½†å‹ç‡éä½ï¼Œå»ºè­°è§€æœ›", 0
            
        shares = int(shares_by_risk)
        cost = shares * price
        
        msg = f"ğŸš€ å»ºè­°è²·é€² {shares} è‚¡ (ç´„ ${cost:.0f})"
        if safe_kelly > 0.2: msg += " ğŸ”¥é‡å€‰æ©Ÿæœƒ"
        
        return msg, shares
    except: return "è¨ˆç®—å¤±æ•—", 0

def identify_k_pattern(df):
    try:
        if len(df) < 3: return "N/A"
        
        last_3 = df.iloc[-3:].copy()
        c = last_3['Close'].values
        o = last_3['Open'].values
        h = last_3['High'].values
        l = last_3['Low'].values
        
        c2, o2, h2, l2 = c[2], o[2], h[2], l[2]
        c1, o1, h1, l1 = c[1], o[1], h[1], l[1]
        c0, o0, h0, l0 = c[0], o[0], h[0], l[0]
        
        body2 = abs(c2 - o2)
        upper2 = h2 - max(c2, o2)
        lower2 = min(c2, o2) - l2
        body1 = abs(c1 - o1)
        
        # --- åˆ¤æ–·é‚è¼¯ ---
        if (c0 < o0) and (abs(c0-o0) > body1 * 2) and \
           (c2 > o2) and (c2 > (o0 + c0)/2) and \
           (c1 < c0 and c1 < c2): 
            return "ğŸŒ… æ™¨æ˜Ÿè½‰æŠ˜ (å¤š)"

        if (c0 > o0) and (abs(c0-o0) > body1 * 2) and \
           (c2 < o2) and (c2 < (o0 + c0)/2) and \
           (c1 > c0 and c1 > c2):
            return "ğŸŒƒ æš®æ˜Ÿè½‰æŠ˜ (ç©º)"

        if (c0 > o0) and (c1 > o1) and (c2 > o2) and \
           (c1 > c0) and (c2 > c1) and \
           (body2 > 0) and (lower2 < body2 * 0.5):
            return "ğŸ’‚â€â™‚ï¸ ç´…ä¸‰å…µ (å¼·å¤š)"

        if (c0 < o0) and (c1 < o1) and (c2 < o2) and \
           (c1 < c0) and (c2 < c1):
            return "ğŸ¦… é»‘ä¸‰é´‰ (å¼·ç©º)"

        if (c2 > o2) and (c1 < o1) and (c2 > o1) and (o2 < c1):
            return "ğŸ”¥ å¤šé ­åå™¬"
        if (c2 < o2) and (c1 > o1) and (c2 < o1) and (o2 > c1):
            return "ğŸ’€ ç©ºé ­åå™¬"

        if (body1 > body2 * 3) and (max(c2, o2) < max(c1, o1)) and (min(c2, o2) > min(c1, o1)):
            return "ğŸ¤° æ¯å­è®Šç›¤ç·š"

        if (lower2 >= body2 * 2) and (upper2 <= body2 * 0.5):
            return "ğŸ”¨ éŒ˜é ­/åŠäºº (æ¸¬åº•)"
        
        if (upper2 >= body2 * 2) and (lower2 <= body2 * 0.5):
            return "ğŸŒ  æµæ˜Ÿ/å€’éŒ˜ (æ¸¬é ‚)"

        if body2 <= (h2 - l2) * 0.1:
            return "âœï¸ åå­—ç·š (è§€æœ›)"

        return "ä¸€èˆ¬éœ‡ç›ª"
    except: return "N/A"

def quick_backtest(df, config, fee=0.0005):
    try:
        close = df['Close']; sigs = pd.Series(0, index=df.index)
        mode = config['mode']
        
        # â˜…â˜…â˜… æ–°å¢ï¼šè®€å–æ˜¯å¦å•Ÿç”¨æ¿¾ç¶² (é è¨­ç‚º Trueï¼Œå³é–‹å•Ÿ) â˜…â˜…â˜…
        use_filter = config.get('ma_filter', True)
        
        if mode == "RSI_MA":
            rsi = ta.rsi(close, length=config.get('rsi_len', 14))
            ma_exit = ta.sma(close, length=config['exit_ma'])
            sigs[rsi < config['entry_rsi']] = 1
            sigs[close > ma_exit] = -1
            # ... (æ¥åœ¨å…¶ä»– elif ä¸‹é¢)
        elif mode == "BOLL_BREAK":
            # ç­–ç•¥ï¼šçªç ´ä¸Šè»Œè²·é€²ï¼Œè·Œç ´ä¸­ç·šè³£å‡º (ACHR å† è»ç­–ç•¥)
            bb = ta.bbands(close, length=20, std=2)
            mid = bb.iloc[:, 1]   # ä¸­è»Œ (20MA)
            upper = bb.iloc[:, 2] # ä¸Šè»Œ
            
            # è¨Šè™Ÿï¼šæ”¶ç›¤åƒ¹ > ä¸Šè»Œ = è²·é€² (1)
            sigs[close > upper] = 1
            # è¨Šè™Ÿï¼šæ”¶ç›¤åƒ¹ < ä¸­è»Œ = è³£å‡º (-1)
            sigs[close < mid] = -1
        elif mode == "MA_CROSS":
            f = ta.sma(close, config['fast_ma']); s = ta.sma(close, config['slow_ma'])
            sigs[(f > s) & (f.shift(1) <= s.shift(1))] = 1
            sigs[(f < s) & (f.shift(1) >= s.shift(1))] = -1
        elif mode == "FUSION":
            rsi = ta.rsi(close, length=config.get('rsi_len', 14))
            ma = ta.ema(close, length=config.get('ma_trend', 200))
            if use_filter:
                sigs[(close > ma) & (rsi < config['entry_rsi'])] = 1
            else:
                sigs[rsi < config['entry_rsi']] = 1
            sigs[rsi > config['exit_rsi']] = -1
        elif mode == "BOLL_RSI":
            rsi = ta.rsi(close, length=config.get('rsi_len', 14))
            bb = ta.bbands(close, length=20, std=2)
            lower = bb.iloc[:, 0]; upper = bb.iloc[:, 2]
            sigs[(close < lower) & (rsi < config['entry_rsi'])] = 1
            sigs[close > upper] = -1
        
        # â˜…â˜…â˜… å„ªåŒ–é‡é»ï¼šRSI_RSI åŠ å…¥è¶¨å‹¢æ¿¾ç¶²é–‹é—œ â˜…â˜…â˜…
        elif mode == "RSI_RSI":
            rsi = ta.rsi(close, length=config.get('rsi_len', 14))
            # åªæœ‰ç•¶ 1.æœ‰è¨­å®šMA ä¸” 2.æ¿¾ç¶²é–‹å•Ÿ æ™‚ï¼Œæ‰æª¢æŸ¥è‚¡åƒ¹æ˜¯å¦ç«™ä¸ŠMA
            if config.get('ma_trend', 0) > 0 and use_filter:
                ma_trend = ta.ema(close, length=config['ma_trend'])
                sigs[(rsi < config['entry_rsi']) & (close > ma_trend)] = 1
            else:
                # æ²’è¨­å®š MA æˆ– ã€Œå¼·åˆ¶é—œé–‰æ¿¾ç¶²ã€ -> åªçœ‹ RSI å¤ ä¸å¤ ä½
                sigs[rsi < config['entry_rsi']] = 1
            
            sigs[rsi > config['exit_rsi']] = -1

        elif "RSI" in mode:
            rsi = ta.rsi(close, length=config.get('rsi_len', 14))
            sigs[rsi < config['entry_rsi']] = 1; sigs[rsi > config['exit_rsi']] = -1
        elif "KD" in mode:
            k = ta.stoch(df['High'], df['Low'], close, k=9, d=3).iloc[:, 0]
            sigs[k < config['entry_k']] = 1; sigs[k > config['exit_k']] = -1
        
        pos=0; ent=0; wins=0; trds=0; rets=[]
        for i in range(len(df)):
            if pos == 0 and sigs.iloc[i] == 1: 
                pos = 1; ent = close.iloc[i]
            elif pos == 1 and sigs.iloc[i] == -1:
                pos = 0; r = (close.iloc[i] - ent) / ent - (fee * 2)
                rets.append(r); trds += 1
                if r > 0: wins += 1
        
        win_rate = float(wins / trds) if trds > 0 else 0.0
        last_sig = sigs.iloc[-1]
        
        stats = {
            "Total_Return": sum(rets)*100, 
            "Win_Rate": win_rate * 100, 
            "Raw_Win_Rate": win_rate,
            "Trades": trds
        }
        return last_sig, stats, sigs
    except Exception as e: return 0, None, None

# ==========================================
# â˜… æ–°å¢æ¨¡çµ„ï¼šç±Œç¢¼å¥åº·åº¦è¨ºæ–· (OBV + CMF è§£è®€)
# ==========================================
def analyze_chip_health(df, cmf_len=20):
    try:
        close = df['Close']
        vol = df['Volume']
        
        # 1. è¨ˆç®— OBV èˆ‡å…¶å‡ç·š (åˆ¤æ–·ç±Œç¢¼è¶¨å‹¢)
        obv = ta.obv(close, vol)
        obv_ma = ta.sma(obv, length=20)
        
        # 2. è¨ˆç®— CMF (åˆ¤æ–·è³‡é‡‘æµå‘åŠ›åº¦)
        cmf = ta.cmf(df['High'], df['Low'], close, vol, length=cmf_len)
        
        curr_obv = obv.iloc[-1]
        curr_obv_ma = obv_ma.iloc[-1]
        curr_cmf = cmf.iloc[-1]
        
        # åƒ¹æ ¼è¶¨å‹¢ (ç°¡å–®åˆ¤æ–·)
        price_trend = "æ¼²" if close.iloc[-1] > close.iloc[-20] else "è·Œ"
        
        msg = ""
        status = "neutral" # healthy, divergence, weak
        
        # --- è¨ºæ–·é‚è¼¯ ---
        
        # A. OBV è¶¨å‹¢åˆ¤æ–·
        if curr_obv > curr_obv_ma:
            obv_msg = "ğŸŸ¢ ç±Œç¢¼å¥åº· (OBVåœ¨å‡ç·šä¸Š)"
        else:
            obv_msg = "âš ï¸ ç±Œç¢¼é¬†å‹• (OBVè·Œç ´å‡ç·š)"
            
        # B. CMF è³‡é‡‘æµå‘
        if curr_cmf > 0.15: flow_msg = "ğŸ”¥ ä¸»åŠ›å¼·åŠ›è²·é€²"
        elif curr_cmf > 0: flow_msg = "ğŸ”¼ è³‡é‡‘ç·©æ­¥æµå…¥"
        elif curr_cmf < -0.15: flow_msg = "ğŸ›‘ ä¸»åŠ›å¤§å¹…å‡ºè²¨"
        else: flow_msg = "ğŸ”½ è³‡é‡‘æµå‡º"
        
        # C. é—œéµï¼šåƒ¹æ ¼èˆ‡ç±Œç¢¼èƒŒé›¢ (Price-Volume Divergence)
        # æƒ…æ³ 1: åƒ¹æ ¼ä¸Šæ¼²ï¼Œä½† OBV å»ä¸‹è·Œ (é‡åƒ¹èƒŒé›¢ - å±éšª)
        if price_trend == "æ¼²" and curr_obv < curr_obv_ma:
            msg = "ğŸ’€ é ‚éƒ¨èƒŒé›¢è­¦æˆ’ï¼šè‚¡åƒ¹å‰µé«˜ä½†ç±Œç¢¼æ²’è·Ÿä¸Š (ä¸»åŠ›åœ¨è·‘)"
            status = "danger"
        # æƒ…æ³ 2: åƒ¹æ ¼ä¸‹è·Œï¼Œä½† CMF å»ç¿»ç´… (åº•éƒ¨å¸ç±Œ - æ©Ÿæœƒ)
        elif price_trend == "è·Œ" and curr_cmf > 0.05:
            msg = "ğŸ’ åº•éƒ¨å¸ç±Œè·¡è±¡ï¼šè‚¡åƒ¹è·Œä½†ä¸»åŠ›è³‡é‡‘é€²å ´"
            status = "gold"
        # æƒ…æ³ 3: åƒ¹æ ¼æ¼² + OBV æ¼² + CMF ç´… (å¥åº·å¤šé ­)
        elif price_trend == "æ¼²" and curr_obv > curr_obv_ma and curr_cmf > 0:
            msg = "ğŸš€ é‡åƒ¹é½Šæšï¼šç±Œç¢¼å®Œç¾é…åˆï¼Œè¶¨å‹¢å¥åº·"
            status = "healthy"
        else:
            msg = f"{obv_msg} | {flow_msg}"
            
        return msg, status, curr_cmf
    except:
        return "ç±Œç¢¼æ•¸æ“šä¸è¶³", "neutral", 0

def plot_chart(df, config, sigs):
    # è¨­å®šåœ–è¡¨ä½ˆå±€ (Row 3 ä½¿ç”¨é›™è»¸: å·¦è»¸ CMF, å³è»¸ OBV)
    fig = make_subplots(
        rows=3, cols=1, 
        shared_xaxes=True, 
        row_heights=[0.6, 0.2, 0.25], # å¢åŠ ä¸‹æ–¹ç±Œç¢¼å€çš„é«˜åº¦
        vertical_spacing=0.03, 
        specs=[[{"secondary_y": False}], [{"secondary_y": False}], [{"secondary_y": True}]]
    )
    
    # --- Row 1: Kç·šåœ–èˆ‡ä¸»åœ–æŒ‡æ¨™ ---
    fig.add_trace(go.Candlestick(x=df.index, open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'], name='Price'), row=1, col=1)
    
    if config.get('ma_trend', 0) > 0:
        ma = ta.ema(df['Close'], length=config['ma_trend'])
        fig.add_trace(go.Scatter(x=df.index, y=ma, name=f"EMA {config['ma_trend']}", line=dict(color='orange', width=1)), row=1, col=1)
        
    if "BOLL" in config['mode']:
        bb = ta.bbands(df['Close'], length=20, std=2)
        fig.add_trace(go.Scatter(x=df.index, y=bb.iloc[:, 2], name="Upper", line=dict(color='rgba(255,255,255,0.3)', width=1)), row=1, col=1)
        fig.add_trace(go.Scatter(x=df.index, y=bb.iloc[:, 0], name="Lower", line=dict(color='rgba(255,255,255,0.3)', width=1), fill='tonexty'), row=1, col=1)

    # --- Row 2: å‰¯åœ– (RSI / KD) ---
    if "RSI" in config['mode'] or config['mode'] == "FUSION":
        rsi = ta.rsi(df['Close'], length=config.get('rsi_len', 14))
        fig.add_trace(go.Scatter(x=df.index, y=rsi, name="RSI", line=dict(color='#b39ddb')), row=2, col=1)
        fig.add_hline(y=config.get('entry_rsi', 30), line_dash="dash", line_color="green", row=2, col=1)
        fig.add_hline(y=config.get('exit_rsi', 70), line_dash="dash", line_color="red", row=2, col=1)
    elif "KD" in config['mode']:
        k = ta.stoch(df['High'], df['Low'], df['Close'], k=9, d=3)
        fig.add_trace(go.Scatter(x=df.index, y=k.iloc[:, 0], name="K", line=dict(color='yellow')), row=2, col=1)
        fig.add_trace(go.Scatter(x=df.index, y=k.iloc[:, 1], name="D", line=dict(color='lightblue')), row=2, col=1)
        fig.add_hline(y=config.get('entry_k', 20), line_dash="dash", line_color="green", row=2, col=1)

    # --- Row 3: å‡ç´šç‰ˆç±Œç¢¼é€è¦– (CMF + OBV) ---
    # 1. CMF (Chaikin Money Flow) - ä½¿ç”¨å·¦è»¸ (secondary_y=False)
    # æ”¹é€²ï¼šä½¿ç”¨ Filled Area (å±±è„ˆåœ–) è€Œä¸æ˜¯ Barï¼Œä¸¦å€åˆ†é¡è‰²
    target_len = config.get('cmf_len', 20)
    cmf = ta.cmf(df['High'], df['Low'], df['Close'], df['Volume'], length=target_len)
    
    # è£½ä½œæ¼¸å±¤è‰²æˆ–æ­£è² åˆ†è‰²
    cmf_color = ['#00E676' if v >= 0 else '#FF5252' for v in cmf] # äº®ç¶ /äº®ç´…
    
    fig.add_trace(go.Bar(
        x=df.index, y=cmf, 
        name=f'è³‡é‡‘æµå‘ CMF({target_len})', 
        marker_color=cmf_color,
        opacity=0.4  # åŠé€æ˜ï¼Œé¿å…æ“‹ä½å¾Œé¢çš„ç·š
    ), row=3, col=1, secondary_y=False)
    
    # åŠ å…¥ CMF é›¶è»¸ç·š
    fig.add_hline(y=0, line_color="gray", line_width=1, row=3, col=1, secondary_y=False)

    # 2. OBV (On Balance Volume) - ä½¿ç”¨å³è»¸ (secondary_y=True)
    # æ”¹é€²ï¼šåŠ å…¥ OBV å‡ç·š (Signal Line)
    obv = ta.obv(df['Close'], df['Volume'])
    obv_ma = ta.sma(obv, length=20)
    
    # ç¹ªè£½ OBV ä¸»ç·š (é’è‰²)
    fig.add_trace(go.Scatter(
        x=df.index, y=obv, 
        name='ç±Œç¢¼ OBV', 
        line=dict(color='cyan', width=2)
    ), row=3, col=1, secondary_y=True)
    
    # ç¹ªè£½ OBV å‡ç·š (é»ƒè‰²è™›ç·š)
    fig.add_trace(go.Scatter(
        x=df.index, y=obv_ma, 
        name='OBVå‡ç·š(20)', 
        line=dict(color='yellow', width=1, dash='dot')
    ), row=3, col=1, secondary_y=True)

    # è²·è³£è¨Šè™Ÿæ¨™è¨˜
    if sigs is not None:
        buy = df[sigs==1]; sell = df[sigs==-1]
        fig.add_trace(go.Scatter(x=buy.index, y=buy['Low']*0.98, mode='markers', marker=dict(symbol='triangle-up', color='#00E676', size=12), name='Buy Signal'), row=1, col=1)
        fig.add_trace(go.Scatter(x=sell.index, y=sell['High']*1.02, mode='markers', marker=dict(symbol='triangle-down', color='#FF5252', size=12), name='Sell Signal'), row=1, col=1)

    # ç‰ˆé¢è¨­å®š
    fig.update_layout(
        height=800, # åŠ é«˜ä¸€é»
        template="plotly_dark", 
        xaxis_rangeslider_visible=False, 
        showlegend=False,
        margin=dict(l=10, r=10, t=30, b=30)
    )
    
    # è¨­å®š Y è»¸æ¨™ç±¤
    fig.update_yaxes(title_text="CMF è³‡é‡‘æµå‘", row=3, col=1, secondary_y=False, range=[-0.5, 0.5]) # å›ºå®š CMF ç¯„åœä½¿å…¶å°ç¨±
    fig.update_yaxes(title_text="OBV ç´¯ç©é‡", row=3, col=1, secondary_y=True, showgrid=False) # éš±è—å³è»¸ç¶²æ ¼é¿å…æ··äº‚

    return fig

def get_strategy_desc(cfg, df=None):
    mode = cfg['mode']
    desc = mode; current_val = ""
    # â˜…â˜…â˜… æ–°å¢ï¼šé¡¯ç¤ºæ¿¾ç¶²ç‹€æ…‹ â˜…â˜…â˜…
    use_filter = cfg.get('ma_filter', True) 

    if df is not None:
        try:
            close = df['Close']
            if "RSI" in mode or mode == "FUSION":
                rsi = ta.rsi(close, length=cfg.get('rsi_len', 14)).iloc[-1]
                current_val += f" | ğŸ¯ ç›®å‰ RSI: {rsi:.1f}"
            if "KD" in mode:
                k = ta.stoch(df['High'], df['Low'], close, k=9, d=3).iloc[-1, 0]
                current_val += f" | ğŸ¯ ç›®å‰ Kå€¼: {k:.1f}"
            if mode == "MA_CROSS":
                f = ta.sma(close, cfg['fast_ma']).iloc[-1]; s = ta.sma(close, cfg['slow_ma']).iloc[-1]
                current_val += f" | ğŸ¯ MA{cfg['fast_ma']}: {f:.1f} / MA{cfg['slow_ma']}: {s:.1f}"
            if "BOLL" in mode:
                bb = ta.bbands(close, length=20, std=2)
                lower = bb.iloc[-1, 0]
                current_val += f" | ğŸ¯ ä¸‹è»Œ: {lower:.1f} (ç¾åƒ¹: {close.iloc[-1]:.1f})"
        except: pass
    
    if mode == "RSI_RSI": 
        desc = f"RSI å€é–“ (è²· < {cfg['entry_rsi']} / è³£ > {cfg['exit_rsi']})"
        if cfg.get('ma_trend', 0) > 0:
            if use_filter: desc += f" (ğŸ›¡ï¸ åš´æ ¼æ¨¡å¼: éœ€ç«™ä¸Š MA{cfg['ma_trend']})"
            else: desc += f" (ğŸ”“ å¯¬é¬†æ¨¡å¼: ç„¡è¦– MA{cfg['ma_trend']})"
    elif mode == "RSI_MA": desc = f"RSI + å‡ç·š (RSI < {cfg['entry_rsi']} è²· / ç ´ MA{cfg['exit_ma']} è³£)"
    elif mode == "KD": desc = f"KD éš¨æ©ŸæŒ‡æ¨™ (K < {cfg['entry_k']} è²· / K > {cfg['exit_k']} è³£)"
    elif mode == "MA_CROSS": desc = f"å‡ç·šäº¤å‰ (MA{cfg['fast_ma']} ç©¿é MA{cfg['slow_ma']})"
    elif mode == "FUSION": desc = f"è¶¨å‹¢ + RSI (ç«™ä¸Š EMA{cfg['ma_trend']} ä¸” RSI < {cfg['entry_rsi']})"
    elif mode == "BOLL_RSI": desc = f"å¸ƒæ—é€šé“ + RSI (ç ´ä¸‹è»Œä¸” RSI < {cfg['entry_rsi']})"
    elif mode == "BOLL_BREAK": desc = f"å¸ƒæ—é€šé“çªç ´ (è¡éä¸Šè»Œè²· / è·Œç ´ä¸­ç·šè³£)"
    return desc + current_val

# ==========================================
# 5. å´é‚Šæ¬„èˆ‡é é¢é…ç½®
# ==========================================
st.sidebar.title("ğŸš€ æˆ°æƒ…å®¤å°èˆª")
app_mode = st.sidebar.radio("é¸æ“‡åŠŸèƒ½æ¨¡çµ„ï¼š", ["ğŸ¤– AI æ·±åº¦å­¸ç¿’å¯¦é©—å®¤", "ğŸ“Š ç­–ç•¥åˆ†æå·¥å…· (å–®è‚¡)", "ğŸŒ² XGBoost å¯¦é©—å®¤", "ğŸ“’ é æ¸¬æ—¥è¨˜ (è‡ªå‹•é©—è­‰)"])

st.sidebar.divider()
st.sidebar.header("âš™ï¸ å…¨åŸŸè¨­å®š")
ai_provider = st.sidebar.selectbox("AI èªè¨€æ¨¡å‹", ["ä¸ä½¿ç”¨", "Gemini (User Defined)"])
gemini_key = ""; gemini_model = "models/gemini-3-pro-preview"

if ai_provider == "Gemini (User Defined)":
    gemini_key = st.sidebar.text_input("Gemini Key", type="password")
    gemini_model = st.sidebar.text_input("Model Name", value="models/gemini-3-pro-preview")

st.sidebar.divider()
st.sidebar.header("ğŸ’° å‡±åˆ©å…¬å¼è¨­å®š")
user_capital = st.sidebar.number_input("ç¸½æœ¬é‡‘ (USD)", value=10000)
user_risk = st.sidebar.number_input("å–®ç­†é¢¨éšª (%)", value=1.0)

if st.sidebar.button("ğŸ”„ æ¸…é™¤å¿«å– (é‡ç½® AI)"):
    st.cache_resource.clear()
    st.rerun()

# ==========================================
# 6. ä¸»ç•«é¢é‚è¼¯
# ==========================================

# ------------------------------------------
# Mode 1: AI æ·±åº¦å­¸ç¿’å¯¦é©—å®¤
# ------------------------------------------
if app_mode == "ğŸ¤– AI æ·±åº¦å­¸ç¿’å¯¦é©—å®¤":
    st.header("ğŸ¤– AI æ·±åº¦å­¸ç¿’å¯¦é©—å®¤")
    st.caption("ç¥ç¶“ç¶²è·¯æ¨¡å‹ (LSTM) | T+5 & T+3 é›™æ¨¡é æ¸¬")
    
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(["ğŸ“ˆ TSM é›™æ ¸å¿ƒæ³¢æ®µ", "ğŸ» EDZ / å®è§€é›·é”", "âš¡ QQQ ç§‘æŠ€è‚¡é€šç”¨è…¦", "SOXL ä¸‰å€æ§“æ¡¿", "ğŸŒŠ MRVL ç‹™æ“Š", "ğŸ¦… TQQQ ç´æŒ‡ç‹", "ğŸ¦– NVDA ä¿¡ä»°å……å€¼"])
    
# === Tab 1: TSM é›™æ ¸å¿ƒæ³¢æ®µ ===
    with tab1:
        st.subheader("ğŸ“ˆ TSM é›™æ ¸å¿ƒæ³¢æ®µé¡§å•")
        st.caption("ç­–ç•¥ï¼šé•·çŸ­é›™æ¨¡å…±æŒ¯ | å† è»åƒæ•¸ï¼šT+5 (70%) + T+3 (30%)")
        
        # 1. å•Ÿå‹•æŒ‰éˆ•
        # ä½¿ç”¨ v8 ç‰ˆæœ¬è™Ÿå¼·è¿«åˆ·æ–° (é¿å…èˆŠè³‡æ–™å¹²æ“¾)
        if st.button("ğŸš€ å•Ÿå‹•é›™æ¨¡å‹åˆ†æ (T+3 & T+5)", key="btn_tsm_gsheet_v8") or 'tsm_result_v8' in st.session_state:
            
            # å¦‚æœ Session è£¡æ²’æœ‰è³‡æ–™ï¼Œå°±è·‘æ¨¡å‹
            if 'tsm_result_v8' not in st.session_state:
                with st.spinner("AI æ­£åœ¨é€²è¡Œé›™é‡é©—è­‰ (æ‡‰ç”¨ Grid Search æœ€ä½³åŒ–)..."):
                    # å‘¼å« T+5
                    p_long, a_long, price, df_viz_long, backtest_score = get_tsm_swing_prediction()
                    # å‘¼å« T+3
                    p_short, a_short, df_viz_short = get_tsm_short_prediction()
                    # å­˜å…¥ Session
                    st.session_state['tsm_result_v8'] = (p_long, a_long, p_short, a_short, price, df_viz_long, backtest_score, df_viz_short)
            
            # è§£åŒ…æ•¸æ“š
            p_long, a_long, p_short, a_short, price, df_viz_long, backtest_score, df_viz_short = st.session_state['tsm_result_v8']
            
            # è™•ç† None çš„æƒ…æ³ (é˜²å‘†)
            p5 = p_long if p_long is not None else 0.5
            p3 = p_short if p_short is not None else 0.5

            # --- é¡¯ç¤ºå³æ™‚åƒ¹æ ¼ ---
            st.metric("TSM å³æ™‚åƒ¹æ ¼", f"${price:.2f}")
            st.divider()

            # ==========================================
            # â˜…â˜…â˜… æ ¸å¿ƒä¿®æ­£ï¼šæ‡‰ç”¨å† è»åƒæ•¸é‚è¼¯ â˜…â˜…â˜…
            # ==========================================
            # æ ¹æ“š Grid Search çµæœï¼š
            # T+5 æœ€ä½³é–€æª» > 0.5
            # T+3 æœ€ä½³é–€æª» > 0.45
            signal_t5 = p5 > 0.5
            signal_t3 = p3 > 0.45

            col1, col2 = st.columns(2)
            
            # å·¦é‚Šï¼šT+5 (è³‡é‡‘ 70%)
            with col1:
                st.info("ğŸ”­ T+5 ä¸»å¸¥ (è³‡é‡‘ 70%)")
                st.write(f"æ¨¡å‹ä¿¡å¿ƒ: `{p5*100:.1f}%`")
                if signal_t5: 
                    st.success(f"ğŸ“ˆ æŒæœ‰è¨Šè™Ÿ (ç›®æ¨™ 12 å¤©)")
                else: 
                    st.warning(f"âš–ï¸ è§€æœ› / ç©ºæ‰‹")

            # å³é‚Šï¼šT+3 (è³‡é‡‘ 30%)
            with col2:
                st.success("âš¡ T+3 å…ˆé‹’ (è³‡é‡‘ 30%)")
                st.write(f"æ¨¡å‹ä¿¡å¿ƒ: `{p3*100:.1f}%`")
                if signal_t3: 
                    st.success(f"ğŸš€ ç‹™æ“Šè¨Šè™Ÿ (ç›®æ¨™ 4 å¤©)")
                else: 
                    st.warning(f"âš–ï¸ è§€æœ› / ç©ºæ‰‹")

            st.divider()
            
            # --- ç¶œåˆæˆ°ç•¥è¨Šè™Ÿ (å† è»é‚è¼¯ UI) ---
            if signal_t5 and signal_t3:
                signal_msg = "ğŸ‘‘ ã€çš‡å† ç´šè²·é»ã€‘é›™æ¨¡å…±æŒ¯ (Full House)"
                desc = "é•·çŸ­ç·šæ¨¡å‹åŒæ™‚è§¸ç™¼ï¼å»ºè­° 100% è³‡é‡‘é€²å ´ (7:3é…ç½®)ï¼Œé€™æ˜¯å›æ¸¬æœŸæœ›å€¼æœ€é«˜çš„æ™‚åˆ»ã€‚"
                color = "#FFD700" # é‡‘è‰²
                bg_color = "rgba(255, 215, 0, 0.1)"
                final_dir = "Bull"
            
            elif signal_t5:
                signal_msg = "ğŸ“ˆ ã€ä¸»å‡æ®µæŒå€‰ã€‘é•·ç·šçºŒæŠ±"
                desc = "T+5 ä¸»å¸¥çœ‹æ¼²ï¼Œå»ºè­°ç¶­æŒ 70% é•·ç·šéƒ¨ä½ã€‚çŸ­ç·š (T+3) å‹•èƒ½ç¨å¼±ï¼Œ30% è³‡é‡‘æš«æ™‚è§€æœ›ã€‚"
                color = "#00c853" # ç¶ è‰²
                bg_color = "rgba(0, 200, 83, 0.1)"
                final_dir = "Bull"

            elif signal_t3:
                signal_msg = "âš¡ ã€çŸ­ç·šæ¸¸æ“Šã€‘å°è³‡å¿«æ‰“"
                desc = "åƒ…çŸ­ç·šæœ‰æ©Ÿæœƒã€‚å»ºè­°åƒ…æŠ•å…¥ 30% è³‡é‡‘å¿«é€²å¿«å‡ºï¼Œä¸¦åš´æ ¼åŸ·è¡Œ 3% åœæã€‚"
                color = "#2962ff" # è—è‰²
                bg_color = "rgba(41, 98, 255, 0.1)"
                final_dir = "Bull" # çŸ­å¤š

            else:
                signal_msg = "ğŸ’¤ ã€å…¨é¢å†·å»ã€‘å»ºè­°ç©ºæ‰‹"
                desc = "é›™æ¨¡ä¿¡å¿ƒçš†ä¸è¶³ï¼Œå¸‚å ´ç¼ºä¹æ˜ç¢ºæ–¹å‘ï¼Œä¿ç•™ç¾é‡‘ç­‰å¾…ä¸‹æ¬¡æ©Ÿæœƒã€‚"
                color = "gray"
                bg_color = "rgba(128, 128, 128, 0.1)"
                final_dir = "Neutral"

            st.markdown(f"""
            <div style="padding:15px; border-radius:10px; border-left:5px solid {color}; background-color:{bg_color};">
                <h3 style="color:{color}; margin:0;">{signal_msg}</h3>
                <p style="margin-top:10px; color:#ddd;">{desc}</p>
                <p style="margin:5px 0 0 0; font-size:0.8em; color:#aaa;">ç¶œåˆä¿¡å¿ƒ: <b>{((p5+p3)/2)*100:.0f}%</b></p>
            </div>
            """, unsafe_allow_html=True)

            # ==========================================
            # â˜…â˜…â˜… Google Sheet å­˜æª”å€ (é‚è¼¯å¾®èª¿) â˜…â˜…â˜…
            # ==========================================
            st.divider()
            c_save, c_chart = st.columns([1, 2])
            
            with c_save:
                st.subheader("ğŸ’¾ é›²ç«¯æˆ°å ±")
                st.caption("å°‡ä»Šæ—¥è¨Šè™Ÿå¯«å…¥è³‡æ–™åº«")
                
                # è‡ªå‹•ä¿®æ­£ï¼šå¦‚æœä¿¡å¿ƒå¤ªä½ï¼Œå¼·åˆ¶è½‰ç‚º Neutral é¿å…äº‚å­˜
                if p5 < 0.4 and p3 < 0.4: final_dir = "Bear"
                avg_conf = (p5 + p3) / 2
                
                if st.button("ğŸ“¥ å¯«å…¥è³‡æ–™åº«", key="btn_save_gsheet_v8", use_container_width=True):
                    if final_dir == "Neutral":
                        st.warning("âš ï¸ è¶¨å‹¢ä¸æ˜ï¼Œå»ºè­°ä¸è¨˜éŒ„ã€‚")
                    else:
                        ok, msg = save_prediction_db("TSM", final_dir, avg_conf, price)
                        if ok: 
                            st.success(msg)
                            time.sleep(1)
                            st.rerun()
                        else: 
                            st.warning(msg)
                
                # é¡¯ç¤ºæœ€è¿‘ç´€éŒ„
                df_hist = get_history_df("TSM")
                if not df_hist.empty:
                    st.markdown("---")
                    st.caption("ğŸ“œ é›²ç«¯æœ€è¿‘ç´€éŒ„")
                    st.dataframe(df_hist.tail(3)[['date', 'direction', 'return_pct']], use_container_width=True, hide_index=True)

            # å³é‚Šï¼šç•«å‡ºé›²ç«¯æ­·å²åœ– (ä¿æŒä¸è®Š)
            with c_chart:
                st.subheader("ğŸ“Š é›²ç«¯æˆ°ç¸¾å›é¡§")
                with st.spinner("ğŸ¤– å°å¸³ä¸­..."):
                    updated_count = verify_performance_db()
                    if updated_count > 0:
                        st.toast(f"ğŸ‰ å·²çµç®— {updated_count} ç­†äº¤æ˜“ï¼", icon="ğŸ’°")
                        time.sleep(1); st.rerun()
                
                df_hist = get_history_df("TSM")
                if not df_hist.empty and len(df_hist) > 1:
                    fig_rec = make_subplots(specs=[[{"secondary_y": True}]])
                    fig_rec.add_trace(go.Scatter(x=df_hist['date'], y=df_hist['entry_price'], name="ç´€éŒ„é»ä½", line=dict(color='gray', width=2)), secondary_y=False)
                    fig_rec.add_trace(go.Scatter(x=df_hist['date'], y=df_hist['confidence'], name="AI ä¿¡å¿ƒ", line=dict(color='#ff5252', width=3), mode='lines+markers'), secondary_y=True)
                    
                    if 'status' in df_hist.columns:
                        wins = df_hist[df_hist['status'] == 'Win']
                        if not wins.empty:
                            fig_rec.add_trace(go.Scatter(x=wins['date'], y=wins['confidence'], mode='markers', marker=dict(symbol='star', size=15, color='gold'), name="ç²åˆ©"), secondary_y=True)

                    fig_rec.update_layout(height=350, margin=dict(t=30, b=20, l=10, r=10), hovermode="x unified")
                    st.plotly_chart(fig_rec, use_container_width=True)
                else:
                    st.info("ğŸ“‰ è³‡æ–™ä¸è¶³ï¼Œè«‹ç´¯ç©æ›´å¤šç´€éŒ„ã€‚")

            # ==========================================
            # â˜…â˜…â˜… å›æ¸¬åœ–è¡¨å€ (å®Œæ•´ä¿ç•™) â˜…â˜…â˜…
            # ==========================================
            if df_viz_long is not None:
                st.divider()
                st.caption(f"ğŸ”­ T+5 æ³¢æ®µå›æ¸¬ (æ“¬åˆåº¦: {backtest_score*100:.1f}%) - æœ€ä½³é–€æª» > 0.5")
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                fig.add_trace(go.Scatter(x=df_viz_long['Date'], y=df_viz_long['Price'], name="è‚¡åƒ¹", line=dict(color='gray')), secondary_y=False)
                
                # æ›´æ–°ï¼šé¡¯ç¤ºæ–°çš„å† è»é–€æª» 0.5
                buy = df_viz_long[df_viz_long['Prob'] > 0.5]
                if not buy.empty: fig.add_trace(go.Scatter(x=buy['Date'], y=buy['Price'], mode='markers', marker=dict(color='cyan', size=8, symbol='triangle-up'), name='Buy Signal'), secondary_y=False)
                
                fig.add_trace(go.Scatter(x=df_viz_long['Date'], y=df_viz_long['Prob'], name="ä¿¡å¿ƒ", line=dict(color='rgba(0,255,255,0.5)')), secondary_y=True)
                fig.add_hline(y=0.5, line_dash="dot", line_color="cyan", secondary_y=True)
                fig.update_layout(height=350, margin=dict(t=10, b=10))
                st.plotly_chart(fig, use_container_width=True)

            if df_viz_short is not None:
                st.caption("âš¡ T+3 ç‹™æ“Šå›æ¸¬ - æœ€ä½³é–€æª» > 0.45")
                fig_s = make_subplots(specs=[[{"secondary_y": True}]])
                fig_s.add_trace(go.Scatter(x=df_viz_short['Date'], y=df_viz_short['Price'], name="è‚¡åƒ¹", line=dict(color='gray')), secondary_y=False)
                
                # æ›´æ–°ï¼šé¡¯ç¤ºæ–°çš„å† è»é–€æª» 0.45
                buy_s = df_viz_short[df_viz_short['Prob'] > 0.45]
                if not buy_s.empty: fig_s.add_trace(go.Scatter(x=buy_s['Date'], y=buy_s['Price'], mode='markers', marker=dict(color='orange', size=10, symbol='star'), name='Sniper Buy'), secondary_y=False)
                
                fig_s.add_trace(go.Scatter(x=df_viz_short['Date'], y=df_viz_short['Prob'], name="çŸ­ç·šä¿¡å¿ƒ", line=dict(color='rgba(255,165,0,0.5)')), secondary_y=True)
                fig_s.add_hline(y=0.45, line_dash="dot", line_color="orange", secondary_y=True)
                fig_s.update_layout(height=350, margin=dict(t=10, b=10))
                st.plotly_chart(fig_s, use_container_width=True)
                
    # === Tab 2: EDZ / Macro ===
    with tab2:
        st.subheader("å…¨çƒé¢¨éšªé›·é”")
        target_risk = st.selectbox("é¸æ“‡ç›£æ¸¬å°è±¡", ["EDZ", "GC=F", "CL=F", "HG=F"])
        if st.button(f"åˆ†æ {target_risk}", key="btn_macro") or f'macro_{target_risk}' in st.session_state:
            if f'macro_{target_risk}' not in st.session_state:
                with st.spinner("AI åˆ†æå®è§€æ•¸æ“š..."):
                    feat_map = { 'China': "FXI", 'DXY': "DX-Y.NYB", 'Rates': "^TNX", 'Copper': "HG=F" }
                    prob, acc = get_macro_prediction(target_risk, feat_map)
                    price = get_real_live_price(target_risk) or 0
                    st.session_state[f'macro_{target_risk}'] = (prob, acc, price)
            
            prob, acc, price = st.session_state[f'macro_{target_risk}']
            if prob is not None:
                c1, c2, c3 = st.columns(3)
                c1.metric("ç¾åƒ¹", f"${price:.2f}")
                c2.metric("æ¨¡å‹æº–åº¦", f"{acc*100:.1f}%")
                
                direction = "Bull" if prob > 0.5 else "Bear"
                conf = prob if prob > 0.5 else 1 - prob
                
                if prob > 0.6:
                    c3.metric("è¶¨å‹¢æ–¹å‘", "ğŸ“ˆ å‘ä¸Š", delta=f"ä¿¡å¿ƒ {conf*100:.1f}%")
                    if target_risk == "EDZ": st.error("âš ï¸ å¸‚å ´é¿éšªæƒ…ç·’é«˜æ¼²ï¼")
                elif prob < 0.4:
                    c3.metric("è¶¨å‹¢æ–¹å‘", "ğŸ“‰ å‘ä¸‹", delta=f"ä¿¡å¿ƒ {conf*100:.1f}%", delta_color="inverse")
                else:
                    c3.metric("è¶¨å‹¢æ–¹å‘", "ğŸ’¤ éœ‡ç›ª", delta=f"ä¿¡å¿ƒ {conf*100:.1f}%", delta_color="off")
                
                if st.button("ğŸ“¸ è¨˜éŒ„é æ¸¬ (å¿«ç…§)", key=f"save_{target_risk}"):
                    if save_prediction(target_risk, direction, conf, price):
                        st.success("âœ… å·²è¨˜éŒ„ï¼")
                    else: st.warning("âš ï¸ ä»Šå¤©å·²å­˜é")

    # === Tab 3: QQQ Scanner ===
    with tab3:
        st.subheader("QQQ ç§‘æŠ€è‚¡æƒæå™¨")
        tech_list = ["NVDA", "AMD", "AMZN", "MSFT", "GOOGL", "META", "TSLA", "AVGO", "PLTR"]
        if st.button("ğŸš€ æƒæç§‘æŠ€å·¨é ­", key="btn_scan") or 'scan_result' in st.session_state:
            if 'scan_result' not in st.session_state:
                with st.spinner("AI æ­£åœ¨è¨“ç·´é€šç”¨è…¦..."):
                    model, scaler, feats = train_qqq_brain()
                    if model:
                        res = []
                        prog = st.progress(0)
                        for i, t in enumerate(tech_list):
                            p, acc, pr = scan_tech_stock(t, model, scaler, feats)
                            if p: res.append((t, p, acc, pr))
                            prog.progress((i+1)/len(tech_list))
                        prog.empty()
                        res.sort(key=lambda x: x[1]+x[2], reverse=True)
                        st.session_state['scan_result'] = res
            
            if 'scan_result' in st.session_state:
                for tick, p, acc, pr in st.session_state['scan_result']:
                    mark = "ğŸ’" if p > 0.6 and acc > 0.55 else "ğŸ›¡ï¸" if p < 0.4 and acc > 0.55 else "âš ï¸"
                    direction = "ğŸ“ˆ" if p > 0.6 else "ğŸ“‰" if p < 0.4 else "ğŸ’¤"
                    color_str = "green" if p > 0.6 else "red" if p < 0.4 else "gray"
                    col1, col2, col3, col4 = st.columns([2, 2, 3, 2])
                    col1.markdown(f"**{tick}** (${pr:.1f})")
                    col2.markdown(f":{color_str}[{direction} ({p*100:.0f}%)]")
                    col3.caption(f"æº–åº¦: {acc*100:.0f}% {mark}")
                    if col4.button("ğŸ’¾ å­˜å…¥æ—¥è¨˜", key=f"save_{tick}"):
                        dir_str = "Bull" if p > 0.5 else "Bear"
                        conf = p if p > 0.5 else 1 - p
                        if save_prediction(tick, dir_str, conf, pr): st.toast(f"âœ… {tick} å·²å­˜")
                        else: st.toast("âš ï¸ å·²å­˜")

    # === Tab 4 (æˆ–æ–°å¢): SOXL æ§“æ¡¿æˆ°ç¥ ===
    with tab4: # å‡è¨­æ‚¨æƒ³æ”¾åœ¨ç¬¬ä¸€å€‹åˆ†é 
        st.divider()
        st.subheader("ğŸ”¥ SOXL æ§“æ¡¿æˆ°ç¥ (T+3)")
        
        if st.button("ğŸš€ å•Ÿå‹• SOXL é æ¸¬", key="btn_soxl"):
            with st.spinner("AI æ­£åœ¨åˆ†æä¹–é›¢ç‡èˆ‡ VIX ææ…ŒæŒ‡æ•¸..."):
                prob_soxl, acc_soxl, price_soxl = get_soxl_short_prediction()
                
                if prob_soxl is not None:
                    col1, col2, col3 = st.columns(3)
                    col1.metric("SOXL ç¾åƒ¹", f"${price_soxl:.2f}")
                    col2.metric("æ¨¡å‹æˆ°åŠ› (F1)", "0.301", "é«˜æ–¼éš¨æ©Ÿ")
                    
                    # é€™è£¡çš„é‚è¼¯ï¼šå› ç‚ºæ¨¡å‹åŠ äº†æ¬Šé‡ï¼Œæ©Ÿç‡é€šå¸¸æœƒæ¯”è¼ƒæ¥µç«¯
                    # > 0.5 å°±æ˜¯æ˜ç¢ºçš„çœ‹æ¼²è¨Šè™Ÿ
                    if prob_soxl > 0.5:
                        col3.success(f"ğŸš€ å¼·åŠ›çœ‹æ¼² (ä¿¡å¿ƒ {prob_soxl*100:.0f}%)")
                        st.caption("ğŸ’¡ è§¸ç™¼æ¢ä»¶ï¼šä¹–é›¢ç‡éå¤§ + VIX é…åˆ + è¼é”å‹•èƒ½")
                    else:
                        col3.warning(f"ğŸ’¤ å‹•èƒ½ä¸è¶³ (ä¿¡å¿ƒ {prob_soxl*100:.0f}%)")
                else:
                    st.error("æ•¸æ“šä¸‹è¼‰å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")

# === Tab 5: MRVL ç‹™æ“Š ===
    with tab5:
        st.subheader("ğŸŒŠ MRVL ç‹™æ“Šæ‰‹ (T+3)")
        st.caption("ç­–ç•¥ï¼šé«˜å‹ç‡çŸ­ç·šç‹™æ“Š | å¯¦æˆ°é©—è­‰å‹ç‡ï¼š71.4%")
        
        col_btn, col_info = st.columns([1, 3])
        if col_btn.button("ğŸš€ å•Ÿå‹• MRVL é æ¸¬", key="btn_mrvl"):
            with st.spinner("AI æ­£åœ¨ç„æº–ç›®æ¨™..."):
                prob, acc, price = get_mrvl_prediction()
                
                if prob is not None:
                    c1, c2, c3 = st.columns(3)
                    c1.metric("MRVL ç¾åƒ¹", f"${price:.2f}")
                    # é¡¯ç¤ºå¯¦æˆ°å‹ç‡è€Œéæ¨¡å‹æº–åº¦ï¼Œå› ç‚ºæ¨¡å‹æº–åº¦æœƒèª¤å°
                    c2.metric("å¯¦æˆ°åƒè€ƒå‹ç‡", "71.4%") 
                    
                    # ä½¿ç”¨å›æ¸¬é©—è­‰éçš„ 0.55 é–€æª»
                    if prob > 0.55:
                        c3.success(f"ğŸš€ ç‹™æ“Šè²·é» ({prob*100:.0f}%)")
                        st.divider()
                        st.markdown(f"""
                        <div style="padding:15px; border-left:5px solid #00e676; background-color:rgba(0, 230, 118, 0.1);">
                            <h4 style="color:#00e676; margin:0;">ğŸ¯ Sniper Entry Triggered</h4>
                            <p style="margin:5px 0 0 0; color:#ddd;">ä¿¡å¿ƒåº¦çªç ´ 55% é–€æª»ï¼AI åˆ¤æ–·ç›®å‰ç‚ºé«˜å‹ç‡é€²å ´é»ã€‚å»ºè­°æŒæœ‰ 3 å¤©å¾Œç²åˆ©äº†çµã€‚</p>
                        </div>
                        """, unsafe_allow_html=True)
                    elif prob < 0.4:
                        c3.error(f"ğŸ“‰ é¢¨éšªåé«˜ ({prob*100:.0f}%)")
                        st.info("AI å»ºè­°ç©ºæ‰‹è§€æœ›ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡ç‹™æ“Šæ©Ÿæœƒã€‚")
                    else:
                        c3.info(f"âš–ï¸ ç›¤æ•´ä¸­ ({prob*100:.0f}%)")
                        st.caption("ä¿¡å¿ƒä¸è¶³ 55%ï¼Œä¸å»ºè­°å‡ºæ‰‹ã€‚")
                    
                    st.divider()
                    if st.button("ğŸ’¾ è¨˜éŒ„ MRVL", key="save_mrvl"):
                        d = "Bull" if prob > 0.5 else "Bear"
                        c = prob if prob > 0.5 else 1-prob
                        ok, msg = save_prediction_db("MRVL", d, c, price)
                        if ok: st.success(msg)
                        else: st.warning(msg)
                else: st.error("æ•¸æ“šä¸‹è¼‰å¤±æ•—")
                    
# === Tab 6: TQQQ ç´æŒ‡æˆ°ç¥ (æ›´æ–°ç‚º 48% å ±é…¬ç‡åƒæ•¸) ===
    with tab6:
        st.subheader("ğŸ¦… TQQQ ç´æŒ‡æˆ°ç¥ (T+5)")
        st.caption("ç­–ç•¥ï¼šé«˜é–€æª»æ…£æ€§äº¤æ˜“ | åƒæ•¸å„ªåŒ–ï¼šé–€æª» 0.7 / æŒæœ‰ 5 å¤© / ä¸åœæ")
        
        col_btn, col_info = st.columns([1, 3])
        if col_btn.button("ğŸš€ å•Ÿå‹• TQQQ é æ¸¬", key="btn_tqqq_run"):
            with st.spinner("AI æ­£åœ¨åˆ†æç´æŒ‡å‹•èƒ½æ…£æ€§..."):
                prob, acc, price = get_tqqq_prediction()
                
                if prob is not None:
                    c1, c2, c3 = st.columns(3)
                    c1.metric("TQQQ ç¾åƒ¹", f"${price:.2f}")
                    # é¡¯ç¤ºå›æ¸¬çš„å¯¦æˆ°å‹ç‡ï¼Œçµ¦ä½¿ç”¨è€…ä¿¡å¿ƒ
                    c2.metric("å¯¦æˆ°å‹ç‡", "78.6%") 
                    
                    # -------------------------------------------
                    # â˜… æ‡‰ç”¨å† è»åƒæ•¸ (Grid Search Result)
                    # -------------------------------------------
                    # æœ€ä½³é–€æª»: > 0.7 (éå¸¸åš´æ ¼)
                    if prob > 0.7:
                        c3.success(f"ğŸš€ æ¥µå¼·åŠ›è²·é€² ({prob*100:.0f}%)")
                        st.divider()
                        st.markdown(f"""
                        <div style="padding:15px; border-left:5px solid #FFD700; background-color:rgba(255, 215, 0, 0.1);">
                            <h3 style="color:#FFD700; margin:0;">ğŸ‘‘ God Mode Signal</h3>
                            <p style="margin:5px 0 0 0; color:#ddd;">ä¿¡å¿ƒçªç ´ 70%ï¼æ ¹æ“šå›æ¸¬ï¼Œé€™æ˜¯å‹ç‡ 78% çš„é€²å ´é»ã€‚</p>
                            <ul style="margin-top:10px; color:#aaa;">
                                <li><b>å»ºè­°æŒæœ‰ï¼š</b> 5 å€‹äº¤æ˜“æ—¥ (T+5)</li>
                                <li><b>åœæè¨­å®šï¼š</b> å»ºè­°ä¸è¨­åœæ (å¿½ç•¥æ³¢å‹•)</li>
                            </ul>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # ç¨å¾®æ”¾å¯¬ä¸€é»çš„å€é–“ (0.6 ~ 0.7) é›–ç„¶ä¸æ˜¯æœ€ä½³ï¼Œä½†ä¹Ÿå¯ä»¥åƒè€ƒ
                    elif prob > 0.6:
                        c3.warning(f"ğŸ“ˆ è“„å‹¢å¾…ç™¼ ({prob*100:.0f}%)")
                        st.info("ä¿¡å¿ƒä»‹æ–¼ 60%~70%ï¼Œé›–æœªé”ç¥ç´šè²·é»ï¼Œä½†è¶¨å‹¢åå¤šï¼Œå¯å°é‡è©¦å–®ã€‚")
                        
                    elif prob < 0.4:
                        c3.error(f"ğŸ“‰ é¢¨éšªåé«˜ ({prob*100:.0f}%)")
                        st.info("AI å»ºè­°ç©ºæ‰‹ï¼Œç­‰å¾…å›æª”å¾Œçš„ä¸‹ä¸€æ¬¡çˆ†ç™¼ã€‚")
                    else:
                        c3.info(f"âš–ï¸ è§€æœ›ä¸­ ({prob*100:.0f}%)")
                        st.caption("ä¿¡å¿ƒä¸è¶³ï¼Œå‹•èƒ½ä¸æ˜é¡¯ã€‚")
                    
                    st.divider()
                    if st.button("ğŸ’¾ è¨˜éŒ„ TQQQ", key="save_tqqq_final"):
                        d = "Bull" if prob > 0.6 else "Bear" # è¨˜éŒ„é–€æª»ç¨å¾®å¯¬é¬†ä¸€é»æ–¹ä¾¿çµ±è¨ˆ
                        ok, msg = save_prediction_db("TQQQ", d, prob, price)
                        if ok: st.success(msg)
                        else: st.warning(msg)
                else: st.error("æ•¸æ“šä¸‹è¼‰å¤±æ•—")
                    
# === Tab 7: NVDA ä¿¡ä»°å……å€¼ç«™ (æ›´æ–°ç‚º 24% å ±é…¬ç‡åƒæ•¸) ===
    with tab7:
        st.subheader("ğŸ¦– NVDA ä¿¡ä»°å……å€¼ç«™ (T+5)")
        st.caption("ç­–ç•¥ï¼šHype Mode å‹•èƒ½äº¤æ˜“ | å† è»åƒæ•¸ï¼šé–€æª» 0.6 / æŒæœ‰ 5 å¤© / ä¸åœæ")
        
        col_btn, col_info = st.columns([1, 3])
        if col_btn.button("ğŸš€ å•Ÿå‹• NVDA é æ¸¬", key="btn_nvda"):
            with st.spinner("AI æ­£åœ¨è¨ˆç®—ä¿¡ä»°å„²å€¼é¡åº¦..."):
                prob, acc, price = get_nvda_prediction()
                
                if prob is not None:
                    c1, c2, c3 = st.columns(3)
                    c1.metric("NVDA ç¾åƒ¹", f"${price:.2f}")
                    # é¡¯ç¤ºå¯¦æˆ°å‹ç‡
                    c2.metric("å¯¦æˆ°å‹ç‡", "63.6%") 
                    
                    # -------------------------------------------
                    # â˜… æ‡‰ç”¨å† è»åƒæ•¸ (Grid Search Result)
                    # -------------------------------------------
                    # æœ€ä½³é–€æª»: > 0.6
                    if prob > 0.6:
                        c3.success(f"ğŸš€ ä¿¡ä»°å……æ»¿ ({prob*100:.0f}%)")
                        st.divider()
                        st.markdown(f"""
                        <div style="padding:15px; border-left:5px solid #76b900; background-color:rgba(118, 185, 0, 0.1);">
                            <h3 style="color:#76b900; margin:0;">ğŸ¦– Hype Mode Activated</h3>
                            <p style="margin:5px 0 0 0; color:#ddd;">ä¿¡å¿ƒçªç ´ 60%ï¼AI åµæ¸¬åˆ°ä¸»å‡æ®µè¨Šè™Ÿã€‚</p>
                            <ul style="margin-top:10px; color:#aaa;">
                                <li><b>å»ºè­°æ“ä½œï¼š</b> è²·é€²ä¸¦æŒæœ‰ 5 å€‹äº¤æ˜“æ—¥ (T+5)</li>
                                <li><b>é¢¨éšªæç¤ºï¼š</b> <span style="color:#ff5252">å»ºè­°ä¸è¨­åœæ</span> (AI å›æ¸¬é¡¯ç¤º NVDA æ´—ç›¤åŠ‡çƒˆï¼Œè¨­åœææ˜“è¢«æ´—å‡ºå ´)</li>
                            </ul>
                        </div>
                        """, unsafe_allow_html=True)
                        
                    elif prob > 0.5:
                        c3.warning(f"ğŸ“ˆ è“„åŠ›ä¸­ ({prob*100:.0f}%)")
                        st.info("ä¿¡å¿ƒä»‹æ–¼ 50%~60%ï¼Œå‹•èƒ½æ­£åœ¨ç´¯ç©ï¼Œå¯å°é‡ä½ˆå±€ã€‚")
                        
                    else:
                        c3.error(f"ğŸ“‰ ä¿¡ä»°ä¸è¶³ ({prob*100:.0f}%)")
                        st.info(f"ç›®å‰ä¿¡å¿ƒåƒ… {prob*100:.0f}%ï¼Œå»ºè­°ç©ºæ‰‹è§€æœ›ï¼Œä¸è¦æ¥åˆ€ã€‚")
                    
                    st.divider()
                    if st.button("ğŸ’¾ è¨˜éŒ„ NVDA", key="save_nvda"):
                        d = "Bull" if prob > 0.5 else "Bear"
                        ok, msg = save_prediction_db("NVDA", d, prob, price)
                        if ok: st.success(msg)
                        else: st.warning(msg)
                else: st.error("æ•¸æ“šä¸‹è¼‰å¤±æ•— (è«‹æª¢æŸ¥ç¶²è·¯æˆ– API)")


# ------------------------------------------
# Mode 2: ç­–ç•¥åˆ†æå·¥å…· (å–®è‚¡) - å®Œæ•´ä¿®æ­£ç‰ˆ
# ------------------------------------------
elif app_mode == "ğŸ“Š ç­–ç•¥åˆ†æå·¥å…· (å–®è‚¡)":
    st.header("ğŸ“Š å–®è‚¡ç­–ç•¥åˆ†æ")
    
    # 1. å®šç¾©ç­–ç•¥æ¸…å–® (åŒ…å« ACHR)
    strategies = {
        # === ğŸš€ æ½›åŠ›é£†è‚¡ ===
        "ACHR": { "symbol": "ACHR", "name": "ACHR (é£›è¡Œè¨ˆç¨‹è»Š - å¦–è‚¡)", "category": "ğŸš€ æ½›åŠ›é£†è‚¡", "mode": "BOLL_BREAK" },

        # === ğŸ“Š æŒ‡æ•¸èˆ‡å¤–åŒ¯ ===
        "USD_TWD": { "symbol": "TWD=X", "name": "USD/TWD (ç¾å…ƒå…Œå°å¹£åŒ¯ç‡)", "category": "ğŸ“Š æŒ‡æ•¸/å¤–åŒ¯", "mode": "KD", "entry_k": 25, "exit_k": 70 },
        "QQQ": { "symbol": "QQQ", "name": "QQQ (é‚£æ–¯é”å…‹100 ETF)", "category": "ğŸ“Š æŒ‡æ•¸/å¤–åŒ¯", "mode": "RSI_MA", "entry_rsi": 25, "exit_ma": 20, "rsi_len": 2, "ma_trend": 200, "cmf_len": 30 },
        "QLD": { "symbol": "QLD", "name": "QLD (é‚£æ–¯é”å…‹ 2å€åšå¤š)", "category": "ğŸ“Š æŒ‡æ•¸/å¤–åŒ¯", "mode": "RSI_MA", "entry_rsi": 25, "exit_ma": 20, "rsi_len": 2, "ma_trend": 200, "cmf_len": 25 },
        "TQQQ": { "symbol": "TQQQ", "name": "TQQQ (é‚£æ–¯é”å…‹ 3å€åšå¤š)", "category": "ğŸ“Š æŒ‡æ•¸/å¤–åŒ¯", "mode": "RSI_RSI", "entry_rsi": 30, "exit_rsi": 85, "rsi_len": 2, "ma_trend": 200, "cmf_len": 40 },
        "SOXL_S": { "symbol": "SOXL", "name": "SOXL (è²»åŠ 3å€åšå¤š - ç‹™æ“Š)", "category": "ğŸ“Š æŒ‡æ•¸/å¤–åŒ¯", "mode": "RSI_RSI", "entry_rsi": 10, "exit_rsi": 90, "rsi_len": 2, "ma_trend": 100, "cmf_len": 25 },
        "SOXL_F": { "symbol": "SOXL", "name": "SOXL (è²»åŠ 3å€åšå¤š - å¿«æ”»)", "category": "ğŸ“Š æŒ‡æ•¸/å¤–åŒ¯", "mode": "KD", "entry_k": 10, "exit_k": 75, "cmf_len": 25 },
        "EDZ": { "symbol": "EDZ", "name": "EDZ (æ–°èˆˆå¸‚å ´ 3å€åšç©º - é¿éšª)", "category": "ğŸ“Š æŒ‡æ•¸/å¤–åŒ¯", "mode": "BOLL_RSI", "entry_rsi": 9, "rsi_len": 2, "ma_trend": 20, "cmf_len": 10 },
        
        # === ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡ ===
        "NVDA": { "symbol": "NVDA", "name": "NVDA (AI ç®—åŠ›ä¹‹ç‹)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "FUSION", "entry_rsi": 20, "exit_rsi": 90, "rsi_len": 2, "ma_trend": 200, "vix_max": 32, "rvol_max": 2.5, "cmf_len": 30 },
        "TSM": { "symbol": "TSM", "name": "TSM (å°ç©é›» ADR - æ™¶åœ“ä»£å·¥)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "MA_CROSS", "fast_ma": 5, "slow_ma": 60, "cmf_len": 26 },
        "AVGO": { "symbol": "AVGO", "name": "AVGO (åšé€š - AI ç¶²é€šæ™¶ç‰‡)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "RSI_RSI", "rsi_len": 5, "entry_rsi": 55, "exit_rsi": 85, "ma_trend": 200, "cmf_len": 40 },
        "MRVL": { "symbol": "MRVL", "name": "MRVL (é‚å¨çˆ¾ - ASIC å®¢è£½åŒ–æ™¶ç‰‡)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "RSI_RSI", "rsi_len": 2, "entry_rsi": 20, "exit_rsi": 90, "ma_trend": 100, "ma_filter": False, "cmf_len": 25 },
        "QCOM": { "symbol": "QCOM", "name": "QCOM (é«˜é€š - AI æ‰‹æ©Ÿ/PC)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "RSI_RSI", "rsi_len": 8, "entry_rsi": 30, "exit_rsi": 70, "ma_trend": 100, "cmf_len": 30 },
        "GLW": { "symbol": "GLW", "name": "GLW (åº·å¯§ - ç»ç’ƒåŸºæ¿/å…‰é€šè¨Š)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "RSI_RSI", "rsi_len": 3, "entry_rsi": 30, "exit_rsi": 90, "ma_trend": 0 },
        "ONTO": { "symbol": "ONTO", "name": "ONTO (å®‰åœ– - CoWoS æª¢æ¸¬è¨­å‚™)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "RSI_RSI", "rsi_len": 2, "entry_rsi": 50, "exit_rsi": 65, "ma_trend": 100 },
        "AMD": { "symbol": "AMD", "name": "AMD (è¶…å¾®)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "KD", "entry_k": 20, "exit_k": 80 },
        "MU": { "symbol": "MU", "name": "MU (ç¾å…‰ - è¨˜æ†¶é«”)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "KD", "entry_k": 20, "exit_k": 80, "cmf_len": 20 },
        "SMCI": { "symbol": "SMCI", "name": "SMCI (ç¾è¶…å¾® - ä¼ºæœå™¨å¦–è‚¡)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "BOLL_RSI", "entry_rsi": 15, "rsi_len": 4, "ma_trend": 20, "cmf_len": 10 },
        "ARM": { "symbol": "ARM", "name": "ARM (æ¶æ§‹çŸ½æ™ºè²¡)", "category": "ğŸ¤– AI ç¡¬é«”/æ™¶ç‰‡", "mode": "RSI_MA", "entry_rsi": 35, "exit_ma": 20, "rsi_len": 14, "ma_trend": 50, "cmf_len": 20 },

        # === ğŸ’» è»Ÿé«”/å·¨é ­ ===
        "MSFT": { "symbol": "MSFT", "name": "MSFT (å¾®è»Ÿ)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "RSI_RSI", "entry_rsi": 30, "exit_rsi": 70, "rsi_len": 14, "ma_trend": 200 },
        "GOOGL": { "symbol": "GOOGL", "name": "GOOGL (è°·æ­Œ)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "FUSION", "entry_rsi": 20, "exit_rsi": 90, "rsi_len": 2, "ma_trend": 200, "vix_max": 32, "rvol_max": 2.5 },
        "META": { "symbol": "META", "name": "META (è‡‰æ›¸)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "RSI_RSI", "entry_rsi": 40, "exit_rsi": 90, "rsi_len": 2, "ma_trend": 200 },
        "AMZN": { "symbol": "AMZN", "name": "AMZN (äºé¦¬éœ)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "KD", "entry_k": 20, "exit_k": 85, "cmf_len": 40 },
        "TSLA": { "symbol": "TSLA", "name": "TSLA (ç‰¹æ–¯æ‹‰)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "KD", "entry_k": 20, "exit_k": 80, "cmf_len": 10 },
        "AAPL": { "symbol": "AAPL", "name": "AAPL (è˜‹æœ)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "RSI_MA", "entry_rsi": 30, "exit_ma": 20, "rsi_len": 14, "ma_trend": 200 },
        "PLTR": { "symbol": "PLTR", "name": "PLTR (Palantir - AIåœ‹é˜²)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "RSI_RSI", "entry_rsi": 35, "exit_rsi": 85, "rsi_len": 14, "ma_trend": 50 },
        "CRWD": { "symbol": "CRWD", "name": "CRWD (CrowdStrike - è³‡å®‰)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "RSI_RSI", "entry_rsi": 35, "exit_rsi": 90, "rsi_len": 14, "ma_trend": 100, "cmf_len": 20 },
        "PANW": { "symbol": "PANW", "name": "PANW (Palo Alto - è³‡å®‰)", "category": "ğŸ’» è»Ÿé«”/å·¨é ­", "mode": "KD", "entry_k": 20, "exit_k": 80, "cmf_len": 20 },

        # === ğŸ’Š ç”ŸæŠ€é†«ç™‚ (æ¸›è‚¥è—¥) ===
        "LLY": { "symbol": "LLY", "name": "LLY (ç¦®ä¾† - æ¸›è‚¥è—¥ç‹)", "category": "ğŸ’Š ç”ŸæŠ€é†«ç™‚", "mode": "FUSION", "entry_rsi": 60, "exit_rsi": 80, "rsi_len": 14, "ma_trend": 20, "ma_filter": True, "cmf_len": 20 },
        "NVO": { "symbol": "NVO", "name": "NVO (è«¾å’Œè«¾å¾· - æ¸›è‚¥è—¥)", "category": "ğŸ’Š ç”ŸæŠ€é†«ç™‚", "mode": "MA_CROSS", "fast_ma": 10, "slow_ma": 50 },

        # === ğŸª™ æ•¸ä½è³‡ç”¢ (æ¯”ç‰¹å¹£æ¦‚å¿µ) ===
        "BTC_W": { "symbol": "BTC-USD", "name": "BTC (æ¯”ç‰¹å¹£ - æ³¢æ®µ)", "category": "ğŸª™ æ•¸ä½è³‡ç”¢", "mode": "RSI_RSI", "entry_rsi": 44, "exit_rsi": 65, "rsi_len": 14, "ma_trend": 200, "cmf_len": 40 },
        "BTC_F": { "symbol": "BTC-USD", "name": "BTC (æ¯”ç‰¹å¹£ - é–ƒé›»)", "category": "ğŸª™ æ•¸ä½è³‡ç”¢", "mode": "RSI_RSI", "entry_rsi": 30, "exit_rsi": 50, "rsi_len": 2, "ma_trend": 100, "cmf_len": 40 },
        "MSTR": { "symbol": "MSTR", "name": "MSTR (å¾®ç­–ç•¥ - BTCæ§“æ¡¿)", "category": "ğŸª™ æ•¸ä½è³‡ç”¢", "mode": "RSI_RSI", "entry_rsi": 35, "exit_rsi": 85, "rsi_len": 14, "ma_trend": 20, "cmf_len": 10 },
        "COIN": { "symbol": "COIN", "name": "COIN (Coinbase)", "category": "ğŸª™ æ•¸ä½è³‡ç”¢", "mode": "FUSION", "entry_rsi": 30, "exit_rsi": 90, "rsi_len": 14, "ma_trend": 100 },

        # === âš¡ é›»åŠ›èˆ‡èƒ½æº ===
        "ETN": { "symbol": "ETN", "name": "ETN (ä¼Šé “ - é›»ç¶²)", "category": "âš¡ é›»åŠ›/èƒ½æº", "mode": "RSI_RSI", "rsi_len": 2, "entry_rsi": 40, "exit_rsi": 95, "ma_trend": 200 },
        "VRT": { "symbol": "VRT", "name": "VRT (ç¶­è«¦ - æ¶²å†·)", "category": "âš¡ é›»åŠ›/èƒ½æº", "mode": "RSI_RSI", "rsi_len": 2, "entry_rsi": 35, "exit_rsi": 95, "ma_trend": 100 },
        "OKLO": { "symbol": "OKLO", "name": "OKLO (å¾®å‹æ ¸é›»)", "category": "âš¡ é›»åŠ›/èƒ½æº", "mode": "RSI_RSI", "rsi_len": 3, "entry_rsi": 50, "exit_rsi": 95, "ma_trend": 0 },
        "SMR": { "symbol": "SMR", "name": "SMR (NuScale - æ ¸èƒ½)", "category": "âš¡ é›»åŠ›/èƒ½æº", "mode": "RSI_RSI", "rsi_len": 3, "entry_rsi": 45, "exit_rsi": 90, "ma_trend": 0, "cmf_len": 14 },

        # === ğŸ‡¹ğŸ‡¼ å°è‚¡ AI æ¬Šå€¼ ===
        "CHT": { "symbol": "2412.TW", "name": "ä¸­è¯é›»", "category": "ğŸ‡¹ğŸ‡¼ å°è‚¡", "mode": "RSI_RSI", "rsi_len": 14, "entry_rsi": 45, "exit_rsi": 70 },
        "HONHAI": { "symbol": "2317.TW", "name": "é´»æµ· (AI ä¼ºæœå™¨ä»£å·¥)", "category": "ğŸ‡¹ğŸ‡¼ å°è‚¡", "mode": "KD", "entry_k": 20, "exit_k": 80 },
        "QUANTA": { "symbol": "2382.TW", "name": "å»£é” (AI ä¼ºæœå™¨é¾é ­)", "category": "ğŸ‡¹ğŸ‡¼ å°è‚¡", "mode": "RSI_MA", "entry_rsi": 40, "exit_ma": 20, "rsi_len": 14, "ma_trend": 60 },
        "MEDIATEK": { "symbol": "2454.TW", "name": "è¯ç™¼ç§‘ (æ‰‹æ©Ÿæ™¶ç‰‡)", "category": "ğŸ‡¹ğŸ‡¼ å°è‚¡", "mode": "RSI_RSI", "entry_rsi": 30, "exit_rsi": 80, "rsi_len": 14, "ma_trend": 0 },

        # === ğŸ›¡ï¸ é˜²ç¦¦/å‚³ç”¢/åŸç‰©æ–™ ===
        "KO": { "symbol": "KO", "name": "KO (å¯å£å¯æ¨‚)", "category": "ğŸ›¡ï¸ é˜²ç¦¦/å‚³ç”¢", "mode": "RSI_RSI", "rsi_len": 2, "entry_rsi": 30, "exit_rsi": 90, "ma_trend": 0, "cmf_len": 20 },
        "JNJ": { "symbol": "JNJ", "name": "JNJ (å¬Œç”Ÿ)", "category": "ğŸ›¡ï¸ é˜²ç¦¦/å‚³ç”¢", "mode": "RSI_RSI", "rsi_len": 6, "entry_rsi": 25, "exit_rsi": 90, "ma_trend": 200, "cmf_len": 20 },
        "PG": { "symbol": "PG", "name": "PG (å¯¶åƒ‘)", "category": "ğŸ›¡ï¸ é˜²ç¦¦/å‚³ç”¢", "mode": "RSI_RSI", "rsi_len": 6, "entry_rsi": 20, "exit_rsi": 80, "ma_trend": 0, "cmf_len": 30 },
        "BA": { "symbol": "BA", "name": "BA (æ³¢éŸ³)", "category": "ğŸ›¡ï¸ é˜²ç¦¦/å‚³ç”¢", "mode": "RSI_RSI", "rsi_len": 6, "entry_rsi": 15, "exit_rsi": 60, "ma_trend": 0, "cmf_len": 25 },
        "JPM": { "symbol": "JPM", "name": "JPM (æ‘©æ ¹å¤§é€š)", "category": "ğŸ›¡ï¸ é˜²ç¦¦/å‚³ç”¢", "mode": "RSI_RSI", "entry_rsi": 30, "exit_rsi": 80, "rsi_len": 14, "ma_trend": 200 },
        "COST": { "symbol": "COST", "name": "COST (å¥½å¸‚å¤š)", "category": "ğŸ›¡ï¸ é˜²ç¦¦/å‚³ç”¢", "mode": "MA_CROSS", "fast_ma": 20, "slow_ma": 60 },
        
        "GC": { "symbol": "GC=F", "name": "Gold (é»ƒé‡‘æœŸè²¨)", "category": "â›ï¸ åŸç‰©æ–™", "mode": "RSI_RSI", "entry_rsi": 30, "exit_rsi": 70, "rsi_len": 14 },
        "CL": { "symbol": "CL=F", "name": "Crude Oil (åŸæ²¹æœŸè²¨)", "category": "â›ï¸ åŸç‰©æ–™", "mode": "KD", "entry_k": 20, "exit_k": 80 },
        "HG": { "symbol": "HG=F", "name": "Copper (éŠ…æœŸè²¨)", "category": "â›ï¸ åŸç‰©æ–™", "mode": "RSI_MA", "entry_rsi": 30, "exit_ma": 50, "rsi_len": 14 }
    }
    
    # 2. è£½ä½œåˆ†é¡é¸å–® (å…ˆåŸ·è¡Œ)
    all_categories = sorted(list(set(s['category'] for s in strategies.values())))
    selected_cat = st.selectbox("ğŸ“‚ æ­¥é©Ÿä¸€ï¼šé¸æ“‡æ¿å¡Šåˆ†é¡", all_categories)
    
    # 3. æ ¹æ“šåˆ†é¡ç¯©é¸è‚¡ç¥¨ (æ¬¡åŸ·è¡Œ)
    cat_strategies = {k: v for k, v in strategies.items() if v['category'] == selected_cat}
    target_key = st.selectbox("ğŸ“ æ­¥é©ŸäºŒï¼šé¸æ“‡å…·é«”æ¨™çš„", list(cat_strategies.keys()), format_func=lambda x: cat_strategies[x]['name'])
    
    # 4. å®šç¾© cfg (é—œéµï¼å¿…é ˆåœ¨é¸å–®ä¹‹å¾Œ)
    cfg = strategies[target_key]
    
    # 5. æœ€å¾Œæ‰è®€å–æ•¸æ“š (ç¢ºä¿ cfg å·²ç¶“å­˜åœ¨)
    df = get_safe_data(cfg['symbol'])
    lp = get_real_live_price(cfg['symbol'])
    
    if df is not None and lp:
        prev_close = df['Close'].iloc[-2] if len(df) > 1 else lp
        chg = lp - prev_close
        pct_chg = (chg / prev_close) * 100
        
        current_sig, perf, sigs = quick_backtest(df, cfg)
        win_rate = perf['Raw_Win_Rate'] if perf else 0
        trades_count = perf['Trades'] if perf else 0
        
        kelly_msg, kelly_shares = calculate_kelly_position(df, user_capital, win_rate, user_risk/100, current_sig)
        k_pat = identify_k_pattern(df)
        rsi_val = ta.rsi(df['Close'], 14).iloc[-1]
        fund = get_fundamentals(cfg['symbol'])
        
        with st.container(border=True):
            c1, c2, c3 = st.columns(3)
            c1.metric("å³æ™‚åƒ¹æ ¼", f"${lp:.2f}", f"{chg:.2f} ({pct_chg:.2f}%)")
            
            if trades_count > 0:
                c2.metric("ç­–ç•¥å‹ç‡ (å›æ¸¬)", f"{win_rate*100:.0f}%", delta=f"{trades_count} æ¬¡äº¤æ˜“")
            else:
                c2.metric("ç­–ç•¥å‹ç‡ (å›æ¸¬)", "ç„¡äº¤æ˜“", delta="å€é–“æœªè§¸ç™¼", delta_color="off")
                
            c3.metric("å‡±åˆ©å»ºè­°å€‰ä½", f"{kelly_shares} è‚¡", delta=kelly_msg.split(' ')[0] if 'å»ºè­°' in kelly_msg else "è§€æœ›") 
            
            st.info(f"ğŸ’¡ å‡±åˆ©è§€é»: {kelly_msg}")
            
            # --- â˜…â˜…â˜… æ–°å¢ï¼šç±Œç¢¼è¨ºæ–·é¢æ¿ â˜…â˜…â˜… ---
            chip_msg, chip_status, cmf_val = analyze_chip_health(df, cmf_len=cfg.get('cmf_len', 20))
            
            # æ ¹æ“šç‹€æ…‹é¡¯ç¤ºä¸åŒé¡è‰²çš„æç¤ºæ¡†
            if chip_status == "danger":
                st.error(f"ğŸ’£ ç±Œç¢¼è¨ºæ–·: {chip_msg}")
            elif chip_status == "gold":
                st.success(f"ğŸ’° ç±Œç¢¼è¨ºæ–·: {chip_msg}")
            elif chip_status == "healthy":
                st.success(f"âœ… ç±Œç¢¼è¨ºæ–·: {chip_msg}")
            else:
                st.warning(f"âš–ï¸ ç±Œç¢¼è¨ºæ–·: {chip_msg}")

            # ç¹ªè£½æ–°ç‰ˆåœ–è¡¨
            fig = plot_chart(df, cfg, sigs)
            st.plotly_chart(fig, use_container_width=True)
            
            # åŠ å…¥åœ–è¡¨è§£è®€èªªæ˜ (å¹«åŠ©ä½ çœ‹æ‡‚)
            with st.expander("ğŸ“– å¦‚ä½•è§£è®€ä¸‹æ–¹ç±Œç¢¼åœ– (Row 3)?"):
                st.markdown("""
                **1. è³‡é‡‘æµå‘ (CMF) - æŸ±ç‹€åœ–/å±±è„ˆ**:
                * **<span style='color:#00E676'>ç¶ è‰²æŸ±ç‹€</span>**: è³‡é‡‘æ·¨æµå…¥ (æ”¶ç›¤åƒ¹æ”¶åœ¨é«˜é»)ã€‚è¶Šé«˜ä»£è¡¨è²·ç›¤è¶Šå¼·ã€‚
                * **<span style='color:#FF5252'>ç´…è‰²æŸ±ç‹€</span>**: è³‡é‡‘æ·¨æµå‡º (æ”¶ç›¤åƒ¹æ”¶åœ¨ä½é»)ã€‚è¶Šä½ä»£è¡¨è³£å£“è¶Šé‡ã€‚
                * **èƒŒé›¢è¨Šè™Ÿ**: è‚¡åƒ¹å‰µæ–°ä½ï¼Œä½†ç´…è‰²æŸ±ç‹€è®ŠçŸ­ (åº•éƒ¨èƒŒé›¢) -> è²·é»ã€‚

                **2. ç±Œç¢¼èƒ½é‡ (OBV) - ç·šæ¢**:
                * **<span style='color:cyan'>é’è‰²å¯¦ç·š (OBV)</span>** vs **<span style='color:yellow'>é»ƒè‰²è™›ç·š (OBVå‡ç·š)</span>**ã€‚
                * **OBV ç©¿é å‡ç·šå‘ä¸Š**: ä¸»åŠ›é€²å ´æ§ç›¤ï¼Œå®‰å…¨ã€‚
                * **OBV è·Œç ´ å‡ç·šå‘ä¸‹**: ä¸»åŠ›æ£„å®ˆï¼Œå±éšªã€‚
                * **é ‚éƒ¨èƒŒé›¢**: è‚¡åƒ¹å‰µæ–°é«˜ï¼Œä½† OBV æ²’æœ‰éå‰é«˜ -> å‡çªç ´ã€‚
                """, unsafe_allow_html=True)

        if fund:
            with st.expander("ğŸ“Š è²¡å ±åŸºæœ¬é¢ & ç±Œç¢¼æ•¸æ“š", expanded=False):
                f1, f2, f3, f4, f5 = st.columns(5)
                
                def check_metric(val, high_good=True, low_good=False, threshold_good=0, threshold_bad=0):
                    if val is None: return "N/A", "off"
                    val = float(val)
                    if high_good:
                        if val > threshold_good: return f"{val:.1f}% âœ…", "normal"
                        if val < threshold_bad: return f"{val:.1f}% âŒ", "inverse"
                        return f"{val:.1f}% âš ï¸", "off"
                    if low_good:
                        if val < threshold_good: return f"{val:.1f}% âœ…", "normal"
                        if val > threshold_bad: return f"{val:.1f}% âŒ", "inverse"
                        return f"{val:.1f}% âš ï¸", "off"
                    return f"{val:.1f}", "off"

                pe_val = fund['pe']
                pe_str = "N/A"; pe_delta = "off"
                if pe_val:
                    if pe_val < 25: pe_str, pe_delta = f"{pe_val:.1f} âœ…", "normal"
                    elif pe_val > 50: pe_str, pe_delta = f"{pe_val:.1f} âŒ", "inverse"
                    else: pe_str, pe_delta = f"{pe_val:.1f} âš ï¸", "off"
                f1.metric("æœ¬ç›Šæ¯” (PE)", pe_str, delta_color=pe_delta)

                eps_val = fund['eps']
                eps_str = "N/A"; eps_delta = "off"
                if eps_val:
                    if eps_val > 0: eps_str, eps_delta = f"${eps_val:.2f} âœ…", "normal"
                    else: eps_str, eps_delta = f"${eps_val:.2f} âŒ", "inverse"
                f2.metric("EPS", eps_str, delta_color=eps_delta)

                m_str, m_delta = check_metric(fund['margin']*100, high_good=True, threshold_good=40, threshold_bad=10)
                f3.metric("æ¯›åˆ©ç‡", m_str, delta_color=m_delta)

                i_str, i_delta = check_metric(fund['inst']*100, high_good=True, threshold_good=60, threshold_bad=20)
                f4.metric("æ³•äººæŒè‚¡", i_str, delta_color=i_delta)

                s_str, s_delta = check_metric(fund['short']*100, low_good=True, threshold_good=5, threshold_bad=15)
                f5.metric("ç©ºå–®æ¯”ä¾‹", s_str, delta_color=s_delta)
        else:
            st.warning("âš ï¸ æš«ç„¡è²¡å ±æ•¸æ“š (API å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦)")

        strat_desc = get_strategy_desc(cfg, df)
        st.markdown(f"**ğŸ› ï¸ ç•¶å‰ç­–ç•¥é‚è¼¯ï¼š** `{strat_desc}`")

        analyze_btn = False 
        if ai_provider == "Gemini (User Defined)" and gemini_key:
            st.divider()
            st.subheader("ğŸ§  Gemini é¦–å¸­åˆ†æå¸«")
            st.info("â„¹ï¸ ç³»çµ±å°‡è‡ªå‹•æŠ“å– Google News æœ€æ–°é ­æ¢ã€‚è‹¥æ‚¨æœ‰é¡å¤–è³‡è¨Š (å¦‚è²¡å ±ç´°ç¯€)ï¼Œå¯åœ¨ä¸‹æ–¹è£œå……ã€‚")
            with st.expander("ğŸ“ è£œå……ç­†è¨˜ (é¸å¡« / Optional)", expanded=False):
                user_notes = st.text_area("ä¾‹å¦‚ï¼šç‡Ÿæ”¶å‰µæ­·å²æ–°é«˜ã€åˆ†æå¸«èª¿å‡è©•ç´š...", height=68)
            analyze_btn = st.button("ğŸš€ å•Ÿå‹• AI æ·±åº¦åˆ†æ (å«æ–°èè§£è®€)")
            
        if analyze_btn and ai_provider == "Gemini (User Defined)":
            with st.spinner("ğŸ” AI æ­£åœ¨çˆ¬å– Google News ä¸¦é€²è¡Œå¤§è…¦é‹ç®—..."):
                news_items = get_news(cfg['symbol'])
                if news_items:
                    with st.expander(f"ğŸ“° AI å·²è®€å– {len(news_items)} å‰‡æœ€æ–°æ–°è", expanded=True):
                        for n in news_items:
                            st.caption(f"â€¢ {n}")
                else:
                    st.warning("âš ï¸ æš«æ™‚æŠ“ä¸åˆ° Google Newsï¼ŒAI å°‡ç´”ä»¥æŠ€è¡“é¢åˆ†æã€‚")
                    news_items = []

                strat_rsi_len = cfg.get('rsi_len', 14)
                strat_val_txt = ""
                if "RSI" in cfg['mode'] or cfg['mode'] == "FUSION":
                    real_rsi = ta.rsi(df['Close'], length=strat_rsi_len).iloc[-1]
                    strat_val_txt = f"Strategy_RSI({strat_rsi_len}):{real_rsi:.1f}"
                elif "KD" in cfg['mode']:
                    k_val = ta.stoch(df['High'], df['Low'], df['Close'], k=9, d=3).iloc[-1, 0]
                    strat_val_txt = f"KD_K(9,3):{k_val:.1f}"
                elif cfg['mode'] == "MA_CROSS":
                    ma_fast = ta.sma(df['Close'], cfg['fast_ma']).iloc[-1]
                    ma_slow = ta.sma(df['Close'], cfg['slow_ma']).iloc[-1]
                    dist = (ma_fast - ma_slow) / ma_slow * 100
                    strat_val_txt = f"MA_Gap:{dist:.2f}%"

                base_rsi = ta.rsi(df['Close'], 14).iloc[-1]
                sig_map = { 1: "ğŸš€ è²·é€²è¨Šè™Ÿ (Buy)", -1: "ğŸ“‰ è³£å‡ºè¨Šè™Ÿ (Sell)", 0: "ğŸ’¤ è§€æœ›/ç„¡è¨Šè™Ÿ (Wait)" }
                human_sig = sig_map.get(int(current_sig), "æœªçŸ¥")

                fund_txt = "ç„¡è²¡å ±æ•¸æ“š"
                if fund:
                    short_trend_str = "N/A"
                    if fund.get('shares_short') and fund.get('shares_short_prev'):
                        change = (fund['shares_short'] - fund['shares_short_prev']) / fund['shares_short_prev']
                        if change > 0.05: short_trend_str = f"ğŸ”´ å¢åŠ  {change*100:.1f}% (ç©ºè»é›†çµ)"
                        elif change < -0.05: short_trend_str = f"ğŸŸ¢ æ¸›å°‘ {abs(change)*100:.1f}% (ç©ºè»å›è£œ)"
                        else: short_trend_str = f"âšª æŒå¹³ ({change*100:.1f}%)"

                    pe_trend_str = "N/A"
                    if fund.get('pe') and fund.get('fwd_pe'):
                        if fund['fwd_pe'] < fund['pe']: pe_trend_str = f"â†˜ï¸ çœ‹å¥½ (é ä¼°PE {fund['fwd_pe']:.1f} < ç•¶å‰)"
                        else: pe_trend_str = f"â†—ï¸ çœ‹å£ (é ä¼°PE {fund['fwd_pe']:.1f} > ç•¶å‰)"

                    rev_g = f"{fund.get('rev_growth', 0)*100:.1f}%" if fund.get('rev_growth') is not None else "N/A"
                    earn_g = f"{fund.get('earn_growth', 0)*100:.1f}%" if fund.get('earn_growth') is not None else "N/A"
                    
                    fund_txt = (
                        f"PEè©•åƒ¹è¶¨å‹¢:{pe_trend_str} | "
                        f"ç©ºå–®è®Šå‹•(MoM):{short_trend_str} | "
                        f"ç©ºå–®æ¯”ä¾‹:{fund.get('short', 0)*100:.1f}% | "
                        f"ç‡Ÿæ”¶æˆé•·(YoY):{rev_g} | "
                        f"ç²åˆ©æˆé•·(YoY):{earn_g} | "
                        f"æ¯›åˆ©ç‡:{fund.get('margin', 0)*100:.1f}%"
                    )

                tech_txt = (
                    f"ã€ç­–ç•¥é—œéµæŒ‡æ¨™ã€‘: {strat_val_txt}\n"
                    f"ã€ç±Œç¢¼èˆ‡åŸºæœ¬é¢ã€‘: {fund_txt}\n"
                    f"ã€å¸‚å ´å¤§ç’°å¢ƒ RSI(14)ã€‘: {base_rsi:.1f}\n"
                    f"ã€å›æ¸¬å‹ç‡ã€‘: {win_rate*100:.0f}%\n"
                    f"ã€ç•¶å‰è¨Šè™Ÿã€‘: {human_sig}"
                )

                def analyze_v2(api_key, symbol, news, tech_txt, k_pattern, model_name, user_input=""):
                    if not HAS_GEMINI: return "No Gemini", "âš ï¸", False
                    try:
                        genai.configure(api_key=api_key)
                        model = genai.GenerativeModel(model_name)
                        news_str = "\n".join([f"- {n}" for n in news]) if news else "ç„¡æœ€æ–°æ–°è"
                        base_prompt = f"""
                        ä½ æ˜¯ä¸€ä½è¯çˆ¾è¡—è³‡æ·±æ“ç›¤æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹ã€Œå‹•æ…‹è¶¨å‹¢æ•¸æ“šã€é€²è¡Œæ·±åº¦åˆ†æï¼š
                        ã€ç›®æ¨™æ¨™çš„ã€‘ï¼š{symbol}
                        ã€ç¶œåˆæ•¸æ“šé¢æ¿ã€‘ï¼š
                        {tech_txt}
                        ã€Kç·šå‹æ…‹ã€‘ï¼š{k_pattern}
                        ã€æœ€æ–°æ–°èç„¦é»ã€‘ï¼š
                        {news_str}
                        ã€ç”¨æˆ¶è£œå……ç­†è¨˜ã€‘ï¼š{user_input}
                        è«‹çµ¦å‡ºåˆ†æå ±å‘Šï¼š
                        1. ğŸ¯ æ ¸å¿ƒè§€é» (å¤š/ç©º/è§€æœ›)
                        2. ğŸ“Š ç±Œç¢¼èˆ‡åŸºæœ¬é¢è§£è®€ (ç‰¹åˆ¥é—œæ³¨ç©ºå–®å¢æ¸›èˆ‡é ä¼°PEçš„è®ŠåŒ–æ„ç¾©)
                        3. ğŸ“° å¸‚å ´æƒ…ç·’
                        4. ğŸ’¡ æ“ä½œå»ºè­°
                        """
                        return model.generate_content(base_prompt).text, "ğŸ§ ", True
                    except Exception as e: return str(e), "âš ï¸", False

                analysis, icon, success = analyze_v2(gemini_key, cfg['symbol'], news_items, tech_txt, k_pat, gemini_model, user_notes)
                if success: st.markdown(analysis)
                else: st.error(f"Gemini é€£ç·šå¤±æ•—: {analysis}")
# ------------------------------------------
# Mode 4: XGBoost å¯¦é©—å®¤ (ä¸‰åˆ€æµçµ‚æ¥µç‰ˆ)
# ------------------------------------------
elif app_mode == "ğŸŒ² XGBoost å¯¦é©—å®¤":
    st.header("ğŸŒ² XGBoost æˆ°ç•¥æŒ‡æ®æ‰€")
    st.caption("é‡å°ä¸åŒå•†å“ç‰¹æ€§ï¼Œåˆ‡æ›å°ˆå±¬ AI å¤§è…¦")

    # 1. é¸æ“‡ç­–ç•¥æ¨¡çµ„
    model_mode = st.radio("é¸æ“‡æˆ°ç•¥æ¨¡çµ„ï¼š", 
        ["âš”ï¸ TSM æ”»æ“Šå‹ (å€‹è‚¡å‹•èƒ½)", "ğŸŒŠ TQQQ è¶¨å‹¢å‹ (æ§“æ¡¿æ³¢æ®µ)", "ğŸ‡¹ğŸ‡¼ å°è‚¡é€£å‹•å‹ (TW Stocks)", "âš¡ èƒ½æºé›»åŠ›å‹ (Oil & Util)", "ğŸ”¥ AI è¶…ç´šé€±æœŸ (AVGO/MU)", "ğŸº ç¸¾å„ªè‚¡é•·æ³¢æ®µ (å­¤ç‹¼ç­–ç•¥)","ğŸ† TQQQ å† è»ç‰ˆ (æ³¢å‹•ç‡ç­–ç•¥)", "ğŸ›¡ï¸ EDZ é¿éšªå‹ (å´©ç›¤åµæ¸¬)"], 
        horizontal=True
    )

    # 2. æ ¹æ“šæ¨¡å¼è¨­å®šé è¨­å€¼èˆ‡èªªæ˜
    if "TSM" in model_mode:
        default_target = "TSM"
        desc = "âœ… å°ˆæ”»ï¼šTSM \n\nğŸ§  é‚è¼¯ï¼šçœ‹é‡ã€Œè¼é”é€£å‹•ã€èˆ‡ã€ŒçŸ­ç·šçˆ†ç™¼åŠ›ã€ã€‚åªè¦è¼é”æ¼²ã€å‹•èƒ½å¼·å°±è¿½ï¼Œä¸éŒ¯éä»»ä½•é­šèº«ã€‚"
    elif "TQQQ" in model_mode:
        default_target = "TQQQ"
        desc = "âœ… å°ˆæ”»ï¼šTQQQ, SOXL, SPXL, MRVL\n\nğŸ§  é‚è¼¯ï¼šçœ‹é‡ã€Œ50æ—¥ç”Ÿå‘½ç·šã€èˆ‡ã€ŒRSIã€ã€‚ç«™ä¸Šå‡ç·šå°±æ­»æŠ±ï¼Œè·Œç ´å°±è·‘ï¼Œå°ˆåƒå¤§æ³¢æ®µã€‚"
        # â˜…â˜…â˜… æ–°å¢é€™ä¸€æ®µ (å°è‚¡è¨­å®š) â˜…â˜…â˜…
    elif "å°è‚¡" in model_mode:
        default_target = "2330"  # é è¨­é¡¯ç¤ºå°ç©é›»
        desc = "âœ… å°ˆæ”»ï¼š0050æˆåˆ†è‚¡ (å¦‚ 2330, 2454, 2603)\n\nğŸ§  é‚è¼¯ï¼šè·Ÿè‘—ã€Œç¾è‚¡æ˜¨æ™šæ”¶ç›¤ã€åšå°è‚¡ã€‚çµåˆå­£ç·šè¶¨å‹¢èˆ‡è²»åŠé€£å‹•ã€‚"
    elif "èƒ½æº" in model_mode:
        default_target = "XLE"
        desc = "âœ… å°ˆæ”»ï¼šèƒ½æº(XLE)ã€æ½”æ·¨èƒ½æº(ICLN)\n\nğŸ§  é‚è¼¯ï¼šçœ‹é‡ã€ŒåŸæ²¹(CL=F)ã€ã€ã€Œå¤©ç„¶æ°£(NG=F)ã€èˆ‡ã€Œç¾å‚µåˆ©ç‡ã€ã€‚"
    elif "é€±æœŸ" in model_mode:
        default_target = "MU"
        desc = "âœ… å°ˆæ”»ï¼šMU \n\nğŸ§  é‚è¼¯ï¼šé€±æœŸå¾ªç’°ã€‚"
    # â˜…â˜…â˜… æ–°å¢ï¼šå­¤ç‹¼ç­–ç•¥ (AVGO å°ˆç”¨) â˜…â˜…â˜…
    elif "é•·æ³¢æ®µ" in model_mode:
        default_target = "AVGO"
        desc = "âœ… å°ˆæ”»ï¼šAVGO, MSFT, AAPL (æ…¢ç‰›è‚¡)\n\nğŸ§  é‚è¼¯ï¼šå­¤ç‹¼ç­–ç•¥ã€‚æ–·çµ• NVDA é€£å‹•ï¼Œåªçœ‹ã€Œé•·æœŸè¶¨å‹¢ (60/120MA)ã€èˆ‡ã€Œé æ¸¬æœªä¾†20æ—¥ã€ã€‚"
    else:
        default_target = "EDZ"
        desc = "âœ… å°ˆæ”»ï¼šEDZ, SQQQ, UVXY, AVGO\n\nğŸ§  é‚è¼¯ï¼šçœ‹é‡ã€ŒVIXææ…Œã€èˆ‡ã€Œç¾å…ƒåŒ¯ç‡ã€ã€‚å¹³æ™‚ç©ºæ‰‹ï¼Œåªæœ‰å¸‚å ´å¿«å´©ç›¤æ™‚æ‰äº®ç‡ˆã€‚"

    st.info(desc)
    target = st.text_input("è¼¸å…¥ä»£è™Ÿ (Target)", value=default_target)
    # ==========================================
    # â˜…â˜…â˜… ä¿®æ­£ï¼šæŠŠæ»‘æ¡¿ç§»åˆ°æŒ‰éˆ•å¤–é¢ï¼Œé€™æ¨£å®ƒæ‰ä¸æœƒæ¶ˆå¤± â˜…â˜…â˜…
    # ==========================================
    st.sidebar.divider()
    st.sidebar.header("ğŸ”§ å›æ¸¬æ™‚å…‰æ©Ÿ")
    
    # ğŸ‘‡ è«‹æŠŠåŸæœ¬é‚£è¡Œæ”¹æˆé€™æ¨£ï¼ŒåŠ ä¸Š key="backtest_slider"
    test_ratio = st.sidebar.slider(
        "å›æ¸¬é•·åº¦ (Test Size)", 
        0.05, 0.5, 0.2, 0.05, 
        key="backtest_slider"  # <--- åŠ é€™å€‹ï¼é€™æ˜¯å®ƒçš„èº«åˆ†è­‰
    )

    if st.button(f"ğŸš€ å•Ÿå‹• {target} AI è¨“ç·´"):
        with st.spinner(f"æ­£åœ¨å¬å–š {model_mode.split()[1]} AI æ¨¡å‹..."):
            try:
                # ==========================================
                # ç­–ç•¥ A: TSM æ”»æ“Šå‹ (å‹•èƒ½ + NVDA é€£å‹•)
                # ==========================================
                if "TSM" in model_mode:
                    # 1. ä¸‹è¼‰æ•¸æ“š (å€‹è‚¡éœ€è¦çœ‹å¤§å“¥ NVDA å’Œ è²»åŠ SOX)
                    tickers = [target, "NVDA", "^SOX"]
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    df.ffill(inplace=True); df.dropna(inplace=True)

                    # 2. ç‰¹å¾µå·¥ç¨‹ (è²ªå©ªå‹•èƒ½ç‰ˆ)
                    df['Target_Ret_1d'] = df[target].pct_change()
                    df['Target_Ret_3d'] = df[target].pct_change(3)
                    df['Target_Ret_5d'] = df[target].pct_change(5)
                    df['NVDA_Ret'] = df['NVDA'].pct_change() # é—œéµå› å­
                    df['SOX_Ret'] = df['^SOX'].pct_change()
                    df['Alpha_NVDA'] = df['Target_Ret_5d'] - df['NVDA'].pct_change(5)
                    df['Vola'] = df[target].rolling(5).std() / df[target]
                    
                    df.dropna(inplace=True)
                    features = ['Target_Ret_1d', 'Target_Ret_3d', 'Target_Ret_5d', 'NVDA_Ret', 'SOX_Ret', 'Alpha_NVDA', 'Vola']

                    # 3. æ¨™ç±¤ (è²ªå©ªï¼šæœªä¾†3å¤©åªè¦æ¼² > 0 å°±è²·)
                    future_ret = df[target].shift(-3) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.0, 1, 0)

                    # 4. æ¨¡å‹åƒæ•¸ (ç©æ¥µå‹ï¼šæ·±æ¨¹ã€é«˜æ¡æ¨£)
                    params = {
                        'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 5, 
                        'subsample': 0.9, 'colsample_bytree': 0.9
                    }
                    look_ahead_days = 3 # é æ¸¬æœªä¾† 3 å¤©

                # ==========================================
                # ç­–ç•¥ B: TQQQ è¶¨å‹¢å‹ (å‡ç´šç‰ˆ - åŠ å…¥æ—¥åœ“é¿éšª)
                # ==========================================
                elif "TQQQ" in model_mode and "å† è»" not in model_mode:
                    # 1. ä¸‹è¼‰æ•¸æ“š (â˜… ä¿®æ”¹ 1: åŠ å…¥ JPY=X å’Œ VIX)
                    
                    tickers = [target, "QQQ"]
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    
                    df.ffill(inplace=True); df.dropna(inplace=True)

                    # 2. ç‰¹å¾µå·¥ç¨‹ (â˜… é—œéµä¿®æ”¹ï¼šç§»é™¤ Vola)
                    # æˆ‘å€‘åªç•™å‡ç·šå’Œ RSIï¼Œå› ç‚ºæ³¢å‹•ç‡(Vola)æœƒåœ¨å™´å‡ºæ®µåš‡è·‘ AI
                    df['SMA_50'] = ta.sma(df[target], length=50) 
                    df['Bias_50'] = (df[target] - df['SMA_50']) / df['SMA_50'] 
                    df['RSI'] = ta.rsi(df[target], length=14)
                    df['Ret_5d'] = df[target].pct_change(5)
                    df['QQQ_Ret_5d'] = df['QQQ'].pct_change(5)
                    
                    df.dropna(inplace=True)
                    # â˜… ç‰¹å¾µåˆ—è¡¨ï¼šåªæœ‰ç´”ç²¹çš„è¶¨å‹¢èˆ‡å‹•èƒ½
                    features = ['Bias_50', 'RSI', 'Ret_5d', 'QQQ_Ret_5d'] 
                    
                    # 3. æ¨™ç±¤ (é æ¸¬æœªä¾† 5 å¤©)
                    future_ret = df[target].shift(-5) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.0, 1, 0)

                    # 4. æ¨¡å‹åƒæ•¸ (ç¶­æŒé«˜åæ‡‰é€Ÿåº¦)
                    params = {
                        'n_estimators': 150,    
                        'learning_rate': 0.08, 
                        'max_depth': 3,         
                        'min_child_weight': 3,  
                        'gamma': 0.2,           
                        'subsample': 0.8, 
                        'colsample_bytree': 0.8
                    }
                    look_ahead_days = 5 
                    
                    # æ¬Šé‡è¨­å®š
                    weight_multiplier = 1.2 
                    buy_threshold = 0.50
                    
                    
                # ==========================================
                # ç­–ç•¥ D: å°è‚¡é€£å‹•å‹ (æœ€çµ‚ç²åˆ©ç‰ˆï¼šé–å®š 3y + ç©æ¥µåƒæ•¸)
                # ==========================================
                elif "å°è‚¡" in model_mode:
                    # 1. è™•ç†ä»£è™Ÿ
                    if not target.endswith(".TW") and not target.endswith(".TWO"):
                        target = f"{target}.TW"
                    
                    # 2. ä¸‹è¼‰æ•¸æ“š (â˜… é—œéµä¿®æ­£ 1ï¼šçµ•å°è¦ç”¨ "3y")
                    # 5y æœƒè®“ AI è®Šå¾—å¤ªè†½å°ï¼›3y æ‰èƒ½é‡ç¾æ‚¨çœ‹åˆ°çš„é£†æ¼²æ›²ç·š
                    tickers = [target, "^SOX", "QQQ", "NVDA"]
                    
                    st.write(f"ğŸš€ å•Ÿå‹•å°è‚¡ç­–ç•¥ (5å¹´ç©æ¥µç‰ˆ)ï¼Œé–å®šï¼š{target}...")
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    
                    # 3. è£œå€¼ç­–ç•¥
                    df.ffill(inplace=True)
                    df.dropna(inplace=True)
                    
                    # --- ç‰¹å¾µå·¥ç¨‹ (ä¿æŒå°è‚¡å¿…å‹å› å­) ---
                    df['SOX_Ret'] = df['^SOX'].pct_change()
                    df['QQQ_Ret'] = df['QQQ'].pct_change()
                    df['NVDA_Ret'] = df['NVDA'].pct_change()
                    
                    df['Target_Ret_1d'] = df[target].pct_change()
                    df['Target_Ret_5d'] = df[target].pct_change(5)
                    
                    df['SMA_20'] = ta.sma(df[target], length=20)
                    df['SMA_60'] = ta.sma(df[target], length=60)
                    
                    df['Bias_20'] = (df[target] - df['SMA_20']) / df['SMA_20']
                    df['Bias_60'] = (df[target] - df['SMA_60']) / df['SMA_60']
                    
                    df['RSI'] = ta.rsi(df[target], length=14)

                    df.dropna(inplace=True)
                    
                    features = ['Bias_20', 'Bias_60', 'RSI', 'SOX_Ret', 'NVDA_Ret', 'Target_Ret_5d']

                    # 4. æ¨™ç±¤
                    future_ret = df[target].shift(-5) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.0, 1, 0)

                    # 5. æ¨¡å‹åƒæ•¸ (â˜… é—œéµä¿®æ­£ 2ï¼šèª¿é«˜å­¸ç¿’ç‡åˆ° 0.08)
                    # é€™æœƒè®“ç´…ç·šç·Šç·Šå’¬ä½è¡Œæƒ…ï¼Œä¸æœƒåƒåœ– B é‚£æ¨£å¹³å¹³çš„
                    params = {
                        'n_estimators': 150,    
                        'learning_rate': 0.05,  # åŠ å¿«åæ‡‰
                        'max_depth': 4,         
                        'gamma': 0.1,           
                        'subsample': 0.8, 
                        'colsample_bytree': 0.8
                    }
                    
                    weight_multiplier = 1.2
                    buy_threshold = 0.50
                    
                    st.info("ğŸ’¡ ç³»çµ±å„ªåŒ–ï¼šå·²å¼·åˆ¶åˆ‡æ›ç‚ºã€Œ3å¹´ç©æ¥µæ¶æ§‹ã€ï¼Œé€™å°‡æ’é™¤ 2022 ç©ºé ­å¹²æ“¾ï¼Œé‡ç¾å¼·å‹¢è¿½åƒ¹é‚è¼¯ã€‚")
                # ==========================================
                # ç­–ç•¥ E: èƒ½æºé›»åŠ›å‹ (Final - å¸ƒæ—é€†å‹¢ç‰ˆ)
                # ==========================================
                elif "èƒ½æº" in model_mode:
                    # 1. ä¸‹è¼‰æ•¸æ“š (åŠ å…¥ SPY ç•¶æ¿¾ç¶²)
                    tickers = [target, "SPY"]
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    
                    df.ffill(inplace=True); df.dropna(inplace=True)

                    
                    # 2. ç‰¹å¾µå·¥ç¨‹ (å¼•å…¥å¸ƒæ—é€šé“ - ä¿®æ­£ç‰ˆ)
                    
                    # A. å¸ƒæ—é€šé“ (Bollinger Bands)
                    # åƒæ•¸ï¼š20æ—¥ç§»å‹•å¹³å‡ï¼Œ2å€æ¨™æº–å·®
                    bb = ta.bbands(df[target], length=20, std=2)
                    
                    # â˜…â˜…â˜… ä¿®æ­£é»åœ¨æ­¤ï¼šç›´æ¥é‡æ–°å‘½åæ¬„ä½ï¼Œé¿é–‹ .0 çš„å•é¡Œ â˜…â˜…â˜…
                    # pandas_ta çš„ bbands å›ºå®šå›å‚³ 5 å€‹æ¬„ä½ï¼Œé †åºå¦‚ä¸‹ï¼š
                    # Lower(ä¸‹è»Œ), Mid(ä¸­è»Œ), Upper(ä¸Šè»Œ), Bandwidth(å¯¬åº¦), Percent(ä½éš)
                    if bb is not None and not bb.empty:
                        bb.columns = ['BBL', 'BBM', 'BBU', 'BBB', 'BBP']
                        
                        # é€™æ¨£æˆ‘å€‘å°±å¯ä»¥ç”¨ç°¡å–®çš„åç¨±ä¾†å‘¼å«äº†
                        df['BB_Lower'] = bb['BBL']
                        df['BB_Upper'] = bb['BBU']
                        df['BB_Width'] = bb['BBB']
                        
                        # è¨ˆç®— BB_Pct (è‚¡åƒ¹åœ¨é€šé“çš„å“ªå€‹ä½ç½®)
                        # < 0 ä»£è¡¨è·Œç ´ä¸‹è»Œï¼Œ> 1 ä»£è¡¨çªç ´ä¸Šè»Œ
                        df['BB_Pct'] = (df[target] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])
                    else:
                        # è¬ä¸€è¨ˆç®—å¤±æ•—çš„é˜²å‘†æ©Ÿåˆ¶
                        df['BB_Pct'] = 0.5 
                        df['BB_Width'] = 0

                    # B. çŸ­ç·šä¹–é›¢ (Bias_20)
                    df['SMA_20'] = ta.sma(df[target], length=20)
                    df['Bias_20'] = (df[target] - df['SMA_20']) / df['SMA_20']
                    
                    # C. RSI
                    df['RSI'] = ta.rsi(df[target], length=14)
                    
                    # D. å¤§ç›¤ç›¸å°å¼·å¼±
                    df['Alpha_SPY'] = df[target].pct_change(5) - df['SPY'].pct_change(5)

                    df.dropna(inplace=True)
                    
                    # ç‰¹å¾µåˆ—è¡¨ (ä½¿ç”¨æ–°å®šç¾©çš„åç¨±)
                    features = ['BB_Pct', 'BB_Width', 'Bias_20', 'RSI', 'Alpha_SPY']

                    # 3. æ¨™ç±¤ (é æ¸¬æœªä¾† 5 å¤©)
                    future_ret = df[target].shift(-5) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.0, 1, 0)

                    # 4. æ¨¡å‹åƒæ•¸ (ç¨å¾®èª¿é«˜å­¸ç¿’ç‡ï¼Œè®“å®ƒåæ‡‰éˆæ•ä¸€é»)
                    params = {
                        'n_estimators': 200,    
                        'learning_rate': 0.08, # åæ‡‰å¿«ä¸€é»
                        'max_depth': 5,         
                        'gamma': 0.1,           
                        'subsample': 0.8, 
                        'colsample_bytree': 0.8
                    }
                    
                    weight_multiplier = 1.1 
                    buy_threshold = 0.50
                    
                    st.info("ğŸ’¡ èƒ½æºç­–ç•¥é‚è¼¯ (Final)ï¼šæ¡ç”¨ã€Œå¸ƒæ—é€šé“ (Bollinger Bands)ã€ç­–ç•¥ã€‚å°ˆé–€æ•æ‰èƒ½æºè‚¡åœ¨å€é–“ä¸‹ç·£çš„ã€Œè¶…è³£åå½ˆã€æ©Ÿæœƒã€‚")
                # ==========================================
                # ç­–ç•¥ F: AI è¶…ç´šé€±æœŸå‹ (å°ˆé–€è·‘ MU, AVGO)
                # ==========================================
                elif "é€±æœŸ" in model_mode:
                    # 1. ä¸‹è¼‰æ•¸æ“š (ä¸‰åŠå®¢ï¼šç›®æ¨™ã€è¼é”ã€è²»åŠ)
                    tickers = [target, "NVDA", "^SOX"]
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    
                    df.ffill(inplace=True); df.dropna(inplace=True)

                    # 2. ç‰¹å¾µå·¥ç¨‹ (èåˆäº† TSM çš„é€£å‹•æ€§ + TQQQ çš„è¶¨å‹¢æ€§)
                    
                    # A. è€å¤§å¸¶è·¯ (è¼é”é€£å‹•)
                    df['NVDA_Ret'] = df['NVDA'].pct_change()
                    df['SOX_Ret'] = df['^SOX'].pct_change()
                    
                    # B. é•·ç·šä¿è­· (å­£ç·šä¹–é›¢) - é€™æ˜¯æŠ±ä½ 4 å€æ¼²å¹…çš„é—œéµ
                    df['SMA_60'] = ta.sma(df[target], length=60)
                    df['Bias_60'] = (df[target] - df['SMA_60']) / df['SMA_60']
                    
                    # C. ä¸­ç·šå‹•èƒ½ (å‹•é‡)
                    # éå» 10 å¤©æ¼²ä¸æ¼²ï¼Ÿç¢ºèªè¶¨å‹¢æ…£æ€§
                    df['Mom_10'] = df[target] / df[target].shift(10)
                    
                    # D. æ³¢å‹•ç‡ (MU å¾ˆæ´»æ½‘ï¼Œéœ€è¦é€™å€‹ä¾†åˆ¤æ–·æ˜¯å¦éç†±)
                   
                    df.dropna(inplace=True)
                    
                    # ç‰¹å¾µåˆ—è¡¨
                    features = ['NVDA_Ret', 'Bias_60', 'Mom_10', 'SOX_Ret']

                    # 3. æ¨™ç±¤ (â˜…â˜…â˜… é—œéµä¿®æ”¹ï¼šé æ¸¬æœªä¾† 10 å¤© â˜…â˜…â˜…)
                    # è®“ AI å­¸ç¿’ã€ŒæŒæœ‰å…©é€±ã€æœƒä¸æœƒè³ºéŒ¢ï¼Œè€Œä¸æ˜¯ä¸‰å¤©
                    future_ret = df[target].shift(-10) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.0, 1, 0)

                    # 4. æ¨¡å‹åƒæ•¸ (ç¨å¾®åŠ æ·±æ¨¹çš„æ·±åº¦ï¼Œå› ç‚ºé€±æœŸè‚¡æ¯”è¼ƒè¤‡é›œ)
                    params = {
                        'n_estimators': 200,    
                        'learning_rate': 0.05, 
                        'max_depth': 6,         
                        'gamma': 0.1,           
                        'subsample': 0.8, 
                        'colsample_bytree': 0.8
                    }
                    
                    weight_multiplier = 1.15  # ç©æ¥µé€²æ”»
                    buy_threshold = 0.50
                    
                    st.info("ğŸ’¡ è¶…ç´šé€±æœŸé‚è¼¯ï¼šçµåˆã€ŒNVDA é€£å‹•ã€èˆ‡ã€Œ10æ—¥è¶¨å‹¢é æ¸¬ã€ã€‚å°ˆç‚ºæ•æ‰ AVGO èˆ‡ MU çš„æ³¢æ®µå¤§è¡Œæƒ…è¨­è¨ˆï¼Œé¿å…å¤ªæ—©ä¸‹è»Šã€‚")
                # ==========================================
                # ç­–ç•¥ G: ç¸¾å„ªè‚¡é•·æ³¢æ®µ (å­¤ç‹¼ç­–ç•¥ - å°ˆæ²» AVGO)
                # ==========================================
                elif "é•·æ³¢æ®µ" in model_mode:
                    # 1. ä¸‹è¼‰æ•¸æ“š (â˜…é—œéµï¼šåªä¸‹è¼‰å®ƒè‡ªå·±ï¼Œæ–·çµ•å¤–éƒ¨é›œè¨Šâ˜…)
                    tickers = [target] 
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    
                    df.ffill(inplace=True); df.dropna(inplace=True)

                    # 2. ç‰¹å¾µå·¥ç¨‹ (æ¥µç°¡åŒ–ï¼šåªçœ‹ä¸­é•·ç·šè¶¨å‹¢)
                    
                    # A. å­£ç·šè¶¨å‹¢ (60æ—¥)
                    df['SMA_60'] = ta.sma(df[target], length=60)
                    df['Bias_60'] = (df[target] - df['SMA_60']) / df['SMA_60']
                    
                    # B. åŠå¹´ç·šè¶¨å‹¢ (120æ—¥) - â˜…æ–°å¢ï¼šç”¨ä¾†ç¢ºèªå¤§æ ¼å±€
                    df['SMA_120'] = ta.sma(df[target], length=120)
                    df['Bias_120'] = (df[target] - df['SMA_120']) / df['SMA_120']
                    
                    # C. æœˆå‹•èƒ½ (éå»20å¤©æ¼²å¹…)
                    # å–ä»£ RSIï¼Œå› ç‚ºå‹•èƒ½æ²’æœ‰ä¸Šé™ï¼Œä¸æœƒå› ç‚ºæ¼²å¤šå°±è¢«è³£æ‰
                    df['Mom_20'] = df[target] / df[target].shift(20)

                    df.dropna(inplace=True)
                    
                    # ç‰¹å¾µåˆ—è¡¨ï¼šä¹¾æ·¨åˆ°åªå‰©é€™ä¸‰å€‹
                    features = ['Bias_60', 'Bias_120', 'Mom_20']

                    # 3. æ¨™ç±¤ (â˜…é—œéµï¼šé æ¸¬æœªä¾† 20 å¤©/ä¸€å€‹æœˆâ˜…)
                    # å¼·è¿« AI å­¸ç¿’ã€ŒæŒæœ‰é€™å¼µè‚¡ç¥¨ä¸€å€‹æœˆæœƒä¸æœƒè³ºéŒ¢ï¼Ÿã€
                    future_ret = df[target].shift(-20) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.0, 1, 0)

                    # 4. æ¨¡å‹åƒæ•¸ (é™ä½è¤‡é›œåº¦ï¼Œé¿å…æƒ³å¤ªå¤š)
                    params = {
                        'n_estimators': 100,    
                        'learning_rate': 0.05,
                        'max_depth': 4, # æ·ºä¸€é»ï¼Œè®“å®ƒåªæŠ“å¤§æ–¹å‘
                        'gamma': 0.1,           
                        'subsample': 0.8, 
                        'colsample_bytree': 0.8
                    }
                    
                    weight_multiplier = 1.0 
                    buy_threshold = 0.50
                    
                    st.info("ğŸ’¡ å­¤ç‹¼ç­–ç•¥é‚è¼¯ï¼šå°ˆç‚º AVGO é€™ç¨®ã€Œç¨ç«‹èµ°å‹¢ã€çš„æ…¢ç‰›è¨­è¨ˆã€‚åˆ‡æ–· NVDA é€£å‹•ï¼Œåªçœ‹ 60æ—¥/120æ—¥ é•·ç·šè¶¨å‹¢ï¼Œä¸¦é æ¸¬æœªä¾† 20 å¤©èµ°å‹¢ã€‚")
                # ==========================================
                # â˜…â˜…â˜… TQQQ æœ€çµ‚æ”»æ“Šç‰ˆ (å·²ä¿®å¾© SMA_50 éŒ¯èª¤) â˜…â˜…â˜…
                # ==========================================
                elif "å† è»" in model_mode:
                    default_target = "TQQQ"
                    
                    # 1. ä¸‹è¼‰æ•¸æ“š
                    tickers = [target, "QQQ"]
                    st.write(f"ğŸš€ å•Ÿå‹• TQQQ æœ€çµ‚æ”»æ“Šç­–ç•¥ (Trend Only)...")
                    
                    # ç¶­æŒ 3y (å°ˆæ³¨è¿‘æœŸ)
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    
                    df.ffill(inplace=True); df.dropna(inplace=True)

                    # 2. ç‰¹å¾µå·¥ç¨‹
                    
                    # A. å¯Œçˆ¸çˆ¸çš„å‹•å‘ (æœ€é‡è¦)
                    df['QQQ_Ret_5d'] = df['QQQ'].pct_change(5) 
                    
                    # B. è‡ªèº«çš„å‹•èƒ½
                    df['Ret_5d'] = df[target].pct_change(5)
                    
                    # C. è¶¨å‹¢ä¹–é›¢ (ç”Ÿå‘½ç·š)
                    # â˜…â˜…â˜… é—œéµä¿®æ­£ï¼šå¿…é ˆå…ˆå­˜ä¸‹ SMA_50ï¼Œå¦å‰‡æœ€å¾Œçš„å³æ™‚é æ¸¬æœƒå ±éŒ¯ï¼ â˜…â˜…â˜…
                    df['SMA_50'] = ta.sma(df[target], 50)
                    df['Bias_50'] = (df[target] - df['SMA_50']) / df['SMA_50']
                    
                    # D. çŸ­ç·šå¼·å¼±
                    df['RSI'] = ta.rsi(df[target], length=14)

                    df.dropna(inplace=True)
                    
                    # â˜… æœ€çµ‚ç‰¹å¾µåˆ—è¡¨ï¼šåªæœ‰ 4 å€‹ç´”è¶¨å‹¢å› å­
                    features = ['QQQ_Ret_5d', 'Bias_50', 'Ret_5d', 'RSI'] 
                    
                    # 3. æ¨™ç±¤ (é æ¸¬æœªä¾† 5 å¤©)
                    future_ret = df[target].shift(-5) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.0, 1, 0)

                    # 4. æ¨¡å‹åƒæ•¸ (é«˜åæ‡‰é€Ÿåº¦)
                    params = {
                        'n_estimators': 200,    
                        'learning_rate': 0.08,
                        'max_depth': 4,         
                        'min_child_weight': 3,  
                        'gamma': 0.2,           
                        'subsample': 0.8, 
                        'colsample_bytree': 0.8
                    }
                    look_ahead_days = 5 
                    weight_multiplier = 1.2 
                    buy_threshold = 0.50
                    
                    st.info("ğŸ’¡ ç³»çµ±ä¿®å¾©ï¼šå·²è£œå› SMA_50 æ¬„ä½ï¼Œå³æ™‚é æ¸¬åŠŸèƒ½å°‡æ¢å¾©æ­£å¸¸ã€‚")

                # ==========================================
                # ç­–ç•¥ C: EDZ é¿éšªå‹ (å´©ç›¤åµæ¸¬)
                # ==========================================
                else:
                    ref_market = "EEM" if "EDZ" in target else "QQQ"
                    tickers = [target, ref_market, "DX-Y.NYB", "^VIX"]
                    data = yf.download(tickers, period="5y", interval="1d", progress=False)
                    if isinstance(data.columns, pd.MultiIndex): df = data['Close'].copy()
                    else: df = data['Close'].copy()
                    df.ffill(inplace=True); df.dropna(inplace=True)

                    # ç‰¹å¾µ
                    df['Target_Ret_1d'] = df[target].pct_change()
                    df['Market_Ret'] = df[ref_market].pct_change()
                    df['DXY_Ret'] = df['DX-Y.NYB'].pct_change()
                    df['VIX_Level'] = df['^VIX']
                    df['Vola'] = df[target].rolling(5).std() / df[target]
                    
                    df.dropna(inplace=True)
                    features = ['Target_Ret_1d', 'Market_Ret', 'DXY_Ret', 'VIX_Level', 'Vola']

                    # æ¨™ç±¤ (æŠ“å¤§æ³¢å‹• > 2%)
                    future_ret = df[target].shift(-3) / df[target] - 1
                    df['Label'] = np.where(future_ret > 0.02, 1, 0)

                    params = {
                        'n_estimators': 150, 'learning_rate': 0.05, 'max_depth': 3,
                        'subsample': 0.7, 'colsample_bytree': 0.7
                    }
                    look_ahead_days = 3

                # ==========================================
                # é€šç”¨è¨“ç·´æµç¨‹ (ä¿®å¾©ç‰ˆï¼šåŠ å…¥å¼·åˆ¶è½‰å‹ + å›æ¸¬æ»‘æ¡¿)
                # ==========================================
                
                # 1. å¼·åˆ¶å°‡æ‰€æœ‰ç‰¹å¾µè½‰ç‚ºæ•¸å­—
                for col in features:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # 2. æ¸…é™¤ NaN
                df.dropna(inplace=True)

                # ç¢ºä¿é‚„æœ‰è³‡æ–™
                if len(df) < 50:
                    st.error(f"âŒ æ•¸æ“šæ¸…æ´—å¾Œæ¨£æœ¬ä¸è¶³ ({len(df)}ç­†)ï¼Œç„¡æ³•è¨“ç·´ã€‚")
                    st.stop()
                
                X = df[features]
                y = df['Label']
                
                # â˜…â˜…â˜… é—œéµä¿®æ”¹ï¼šä½¿ç”¨æ»‘æ¡¿æ•¸å€¼ä¾†åˆ‡åˆ† â˜…â˜…â˜…
                split = int(len(df) * (1 - test_ratio))
                
                X_train, X_test = X.iloc[:split], X.iloc[split:]
                y_train, y_test = y.iloc[:split], y.iloc[split:]

                # è¨ˆç®—åŸºç¤æ¬Šé‡
                base_weight = (len(y_train) - y_train.sum()) / y_train.sum()
                multiplier = locals().get('weight_multiplier', 1.0) 
                final_weight = base_weight * multiplier

                st.write('âš–ï¸ æ­£åœ¨å¬å–šé›†æˆæ¨¡å‹ä¸‰å·¨é ­ (XGBoost + LightGBM + CatBoost)...')
                
                # 1. è¨“ç·´ XGBoost
                model_xgb = xgb.XGBClassifier(**params, scale_pos_weight=final_weight, random_state=42)
                model_xgb.fit(X_train, y_train)

                # 2. è¨“ç·´ LightGBM (ä¿®æ­£æ¬„ä½åç¨±)
                X_train_lgb = X_train.rename(columns=lambda x: x.replace('_', ''))
                model_lgb = lgb.LGBMClassifier(n_estimators=params['n_estimators'], max_depth=params['max_depth'], learning_rate=params['learning_rate'], random_state=42, verbose=-1, scale_pos_weight=final_weight)
                model_lgb.fit(X_train_lgb, y_train)

                # 3. è¨“ç·´ CatBoost
                model_cat = CatBoostClassifier(iterations=params['n_estimators'], depth=params['max_depth'], learning_rate=params['learning_rate'], random_seed=42, verbose=0, scale_pos_weight=final_weight)
                model_cat.fit(X_train, y_train)

                # 4. é›†æˆåŒ…è£å™¨ (é€™æ˜¯åŸæœ¬çš„ï¼Œæˆ‘å€‘ä¿ç•™å®ƒä¾†åšé æ¸¬)
                class EnsembleWrapper:
                    def __init__(self, models): self.models = models
                    def predict_proba(self, X):
                        p1 = self.models[0].predict_proba(X)[:, 1]
                        X_lgb = X.rename(columns=lambda x: x.replace('_', ''))
                        p2 = self.models[1].predict_proba(X_lgb)[:, 1]
                        p3 = self.models[2].predict_proba(X)[:, 1]
                        avg = (p1 + p2 + p3) / 3
                        return np.vstack([1-avg, avg]).T
                    
                    # â˜… è®“åŒ…è£å™¨ä¹Ÿèƒ½åå‡ºç‰¹å¾µé‡è¦æ€§ (å€Ÿç”¨ XGBoost çš„)
                    @property
                    def feature_importances_(self): return self.models[0].feature_importances_

                model = EnsembleWrapper([model_xgb, model_lgb, model_cat])

                # =========================================================
                # ğŸš€ A/B æ¸¬è©¦é‚è¼¯é–‹å§‹ï¼šå–®æŒ‘ vs ç¾¤æ¯†
                # =========================================================
                
                threshold = locals().get('buy_threshold', 0.5)

                # 1. å–å¾—ã€Œå–®ä¸€ XGBoostã€çš„é æ¸¬
                prob_xgb = model_xgb.predict_proba(X_test)[:, 1]
                signal_xgb = np.where(prob_xgb > threshold, 1, 0)

                # 2. å–å¾—ã€Œé›†æˆä¸‰å·¨é ­ã€çš„é æ¸¬
                y_probs = model.predict_proba(X_test)[:, 1]
                y_pred_custom = np.where(y_probs > threshold, 1, 0) # é€™æ˜¯æœ€çµ‚è¦ç”¨çš„è¨Šè™Ÿ

                # 3. æº–å‚™å›æ¸¬æ•¸æ“š (æ‰¾å‡ºé€™æ®µæ™‚é–“çš„çœŸå¯¦æ¼²è·Œå¹…)
                # ä½¿ç”¨ X_test çš„ç´¢å¼•ä¾†å°æ‡‰åŸå§‹è³‡æ–™çš„æ¼²è·Œå¹…
                if 'Target_Ret_1d' in df.columns:
                    market_ret = df.loc[X_test.index, 'Target_Ret_1d']
                else:
                    # å¦‚æœæ‰¾ä¸åˆ° 1dï¼Œå˜—è©¦ç”¨ target shift ä¾†è¨ˆç®— (Fallback)
                    market_ret = df.loc[X_test.index, target].pct_change().shift(-1).fillna(0)

                # 4. è¨ˆç®—ä¸‰æ¢è³‡é‡‘æ›²ç·š
                # A. è²·é€²æŒæœ‰ (åŸºæº–)
                cum_market = (1 + market_ret).cumprod()

                # B. å–®ä¸€ XGBoost ç­–ç•¥
                strat_ret_xgb = signal_xgb * market_ret
                cum_xgb = (1 + strat_ret_xgb).cumprod()

                # C. é›†æˆæ¨¡å‹ç­–ç•¥
                strat_ret_ens = y_pred_custom * market_ret
                cum_ens = (1 + strat_ret_ens).cumprod()

                # =========================================================
                # ğŸ“Š ç¹ªåœ–å€
                # =========================================================
                st.markdown("### ğŸ† é ‚ä¸Šæˆ°çˆ­ï¼šå–®ä¸€æ¨¡å‹ vs é›†æˆæ¨¡å‹")
                
                # æ•´åˆæ•¸æ“šç•«åœ–
                chart_data = pd.DataFrame({
                    'ğŸ”µ å–®ä¸€ XGBoost': cum_xgb,
                    'ğŸ”´ é›†æˆä¸‰å·¨é ­ (Ensemble)': cum_ens,
                    'ğŸ““ è²·é€²æŒæœ‰ (Benchmark)': cum_market
                }, index=X_test.index)
                
                st.line_chart(chart_data, color=["#0000FF", "#FF0000", "#808080"])

                # é¡¯ç¤ºæœ€çµ‚å ±é…¬ç‡æ•¸æ“šæ¯”è¼ƒ
                ret_xgb = cum_xgb.iloc[-1] - 1
                ret_ens = cum_ens.iloc[-1] - 1
                
                c1, c2 = st.columns(2)
                c1.metric("ğŸ”µ å–®ä¸€ XGB ç¸½å ±é…¬", f"{ret_xgb*100:.1f}%")
                c2.metric("ğŸ”´ é›†æˆæ¨¡å‹ ç¸½å ±é…¬", f"{ret_ens*100:.1f}%", delta=f"{(ret_ens - ret_xgb)*100:.1f}% (vs å–®ä¸€)")

                # =========================================================
                # ğŸ” æ‰¾å›æ¶ˆå¤±çš„ç‰¹å¾µå› å­åœ–
                # =========================================================
                st.markdown("### ğŸ”‘ é—œéµå› å­ (åŸºæ–¼ XGBoost è¦–è§’)")
                st.info("è¨»ï¼šç”±æ–¼é›†æˆæ¨¡å‹ç”±ä¸‰å€‹å¤§è…¦çµ„æˆï¼Œæ­¤è™•é¡¯ç¤ºå…¶ä¸­æœ€å…·ä»£è¡¨æ€§çš„ XGBoost åˆ¤æ–·é‚è¼¯ã€‚")
                
                if hasattr(model_xgb, 'feature_importances_'):
                    feat_imp = pd.DataFrame({
                        'Feature': features, # ç¢ºä¿é€™è£¡çš„ features è®Šæ•¸æ˜¯ä½ ä¸Šé¢å®šç¾©éçš„åˆ—è¡¨
                        'Importance': model_xgb.feature_importances_
                    }).sort_values(by='Importance', ascending=False).head(10)
                    
                    st.bar_chart(feat_imp.set_index('Feature'), horizontal=True)
                # ==========================================
                # å¯¦æˆ°ç‰ˆï¼šæ˜æ—¥æ“ä½œæŒ‡å¼•
                # ==========================================
                st.divider()
                st.subheader(f"ğŸ”® AI å°æ˜æ—¥é–‹ç›¤çš„æˆ°è¡“æŒ‡ä»¤")
                
                # 1. æº–å‚™æœ€æ–°æ•¸æ“š
                last_feat = X.iloc[-1:].copy()
                live_price = get_real_live_price(target)
                
                # æ³¨å…¥å³æ™‚æ•¸æ“š (è®“é æ¸¬æ›´æº–)
                if live_price:
                    if "TQQQ" in model_mode:
                         sma50 = df['SMA_50'].iloc[-1]
                         last_feat['Bias_50'] = (live_price - sma50) / sma50
                         st.caption(f"âš¡ å³æ™‚åƒ¹æ ¼ ${live_price} | å‡ç·šæ•¸æ“šå·²å³æ™‚ä¿®æ­£")
                    elif "TSM" in model_mode:
                         prev_close = df[target].iloc[-2]
                         last_feat['Target_Ret_1d'] = (live_price - prev_close) / prev_close
                         st.caption(f"âš¡ å³æ™‚åƒ¹æ ¼ ${live_price} | å‹•èƒ½æ•¸æ“šå·²å³æ™‚ä¿®æ­£")
                
                # 2. AI è¨ˆç®—å‹ç‡
                prob = model.predict_proba(last_feat)[0][1]
                
                # 3. å–å¾—æ‚¨çš„é–€æª» (TQQQ=0.5, å…¶ä»–é è¨­0.5)
                thresh = locals().get('buy_threshold', 0.5)

                # 4. é¡¯ç¤ºå„€è¡¨æ¿
                c1, c2, c3 = st.columns(3)
                
                # æ¬„ä½ A: å‹ç‡æ•¸å€¼
                c1.metric("AI ä¸Šæ¼²ä¿¡å¿ƒ", f"{prob*100:.1f}%", help=f"è¶…é {thresh*100:.0f}% æ‰æœƒå‹•ä½œ")
                
                # æ¬„ä½ B: è¶¨å‹¢æ–¹å‘
                if prob > thresh:
                    c2.metric("è¶¨å‹¢åˆ¤æ–·", "ğŸ“ˆ å¤šé ­ (Bullish)", delta="åå¤š")
                else:
                    c2.metric("è¶¨å‹¢åˆ¤æ–·", "ğŸ“‰ ç©ºé ­/ç›¤æ•´", delta="-åç©º", delta_color="inverse")
                
                # æ¬„ä½ C: â˜…â˜…â˜… æœ€é‡è¦çš„å¯¦æˆ°æŒ‡ä»¤ â˜…â˜…â˜…
                if prob > thresh:
                    # å‹ç‡å¤ é«˜ -> è²·é€²æˆ–çºŒæŠ±
                    c3.success(f"ğŸ”¥ æŒ‡ä»¤ï¼šæŒæœ‰ / è²·é€²")
                    st.markdown(f"**æ“ä½œå»ºè­°ï¼š**\n- **ç©ºæ‰‹è€…**ï¼šæ˜æ—©é–‹ç›¤è²·é€²ã€‚\n- **æŒæœ‰è€…**ï¼šçºŒæŠ±ï¼Œä¸åœåˆ©ã€‚")
                else:
                    # å‹ç‡ä¸è¶³ -> è³£å‡ºæˆ–è§€æœ›
                    c3.error(f"ğŸ›‘ æŒ‡ä»¤ï¼šè³£å‡º / ç©ºæ‰‹")
                    st.markdown(f"**æ“ä½œå»ºè­°ï¼š**\n- **æŒæœ‰è€…**ï¼šæ˜æ—©é–‹ç›¤**å¸‚åƒ¹è³£å‡º** (ä¸è¦çŒ¶è±«)ã€‚\n- **ç©ºæ‰‹è€…**ï¼šä¿æŒç¾é‡‘ï¼Œä¸è¦é€²å ´ã€‚")
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")




































































































